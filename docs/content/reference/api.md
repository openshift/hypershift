---
################# IMPORTANT ########################
# Document generated by `make api-docs`. DO NOT EDIT
################# IMPORTANT ########################
title: API
---
# HyperShift API Reference
<p>Packages:</p>
<ul>
<li>
<a href="#hypershift.openshift.io%2fv1alpha1">hypershift.openshift.io/v1alpha1</a>
</li>
</ul>
<h2 id="hypershift.openshift.io/v1alpha1">hypershift.openshift.io/v1alpha1</h2>
<p>
<p>Package v1alpha1 contains the HyperShift API.</p>
<p>The HyperShift API enables creating and managing lightweight, flexible, heterogeneous
OpenShift clusters at scale.</p>
<p>HyperShift clusters are deployed in a topology which isolates the &ldquo;control plane&rdquo;
(e.g. etcd, the API server, controller manager, etc.) from the &ldquo;data plane&rdquo; (e.g.
worker nodes and their kubelets, and the infrastructure on which they run). This
enables &ldquo;hosted control plane as a service&rdquo; use cases.</p>
</p>
##HostedCluster { #hypershift.openshift.io/v1alpha1.HostedCluster }
<p>
<p>HostedCluster is the primary representation of a HyperShift cluster and encapsulates
the control plane and common data plane configuration. Creating a HostedCluster
results in a fully functional OpenShift control plane with no attached nodes.
To support workloads (e.g. pods), a HostedCluster may have one or more associated
NodePool resources.</p>
</p>
<table>
<thead>
<tr>
<th>Field</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<code>apiVersion</code></br>
string</td>
<td>
<code>
hypershift.openshift.io/v1alpha1
</code>
</td>
</tr>
<tr>
<td>
<code>kind</code></br>
string
</td>
<td><code>HostedCluster</code></td>
</tr>
<tr>
<td>
<code>metadata</code></br>
<em>
<a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.22/#objectmeta-v1-meta">
Kubernetes meta/v1.ObjectMeta
</a>
</em>
</td>
<td>
Refer to the Kubernetes API documentation for the fields of the
<code>metadata</code> field.
</td>
</tr>
<tr>
<td>
<code>spec</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.HostedClusterSpec">
HostedClusterSpec
</a>
</em>
</td>
<td>
<p>Spec is the desired behavior of the HostedCluster.</p>
<br/>
<br/>
<table>
<tr>
<td>
<code>release</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.Release">
Release
</a>
</em>
</td>
<td>
<p>Release specifies the desired OCP release payload for the hosted cluster.</p>
<p>Updating this field will trigger a rollout of the control plane. The
behavior of the rollout will be driven by the ControllerAvailabilityPolicy
and InfrastructureAvailabilityPolicy.</p>
</td>
</tr>
<tr>
<td>
<code>clusterID</code></br>
<em>
string
</em>
</td>
<td>
<em>(Optional)</em>
<p>ClusterID uniquely identifies this cluster. This is expected to be
an RFC4122 UUID value (xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx in
hexadecimal values).
As with a Kubernetes metadata.uid, this ID uniquely identifies this
cluster in space and time.
This value identifies the cluster in metrics pushed to telemetry and
metrics produced by the control plane operators. If a value is not
specified, an ID is generated. After initial creation, the value is
immutable.</p>
</td>
</tr>
<tr>
<td>
<code>infraID</code></br>
<em>
string
</em>
</td>
<td>
<em>(Optional)</em>
<p>InfraID is a globally unique identifier for the cluster. This identifier
will be used to associate various cloud resources with the HostedCluster
and its associated NodePools.</p>
</td>
</tr>
<tr>
<td>
<code>platform</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.PlatformSpec">
PlatformSpec
</a>
</em>
</td>
<td>
<p>Platform specifies the underlying infrastructure provider for the cluster
and is used to configure platform specific behavior.</p>
</td>
</tr>
<tr>
<td>
<code>controllerAvailabilityPolicy</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.AvailabilityPolicy">
AvailabilityPolicy
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>ControllerAvailabilityPolicy specifies the availability policy applied to
critical control plane components. The default value is SingleReplica.</p>
<p>
Value must be one of:
&#34;HighlyAvailable&#34;, 
&#34;SingleReplica&#34;
</p>
</td>
</tr>
<tr>
<td>
<code>infrastructureAvailabilityPolicy</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.AvailabilityPolicy">
AvailabilityPolicy
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>InfrastructureAvailabilityPolicy specifies the availability policy applied
to infrastructure services which run on cluster nodes. The default value is
SingleReplica.</p>
<p>
Value must be one of:
&#34;HighlyAvailable&#34;, 
&#34;SingleReplica&#34;
</p>
</td>
</tr>
<tr>
<td>
<code>dns</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.DNSSpec">
DNSSpec
</a>
</em>
</td>
<td>
<p>DNS specifies DNS configuration for the cluster.</p>
</td>
</tr>
<tr>
<td>
<code>networking</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.ClusterNetworking">
ClusterNetworking
</a>
</em>
</td>
<td>
<p>Networking specifies network configuration for the cluster.</p>
</td>
</tr>
<tr>
<td>
<code>autoscaling</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.ClusterAutoscaling">
ClusterAutoscaling
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>Autoscaling specifies auto-scaling behavior that applies to all NodePools
associated with the control plane.</p>
</td>
</tr>
<tr>
<td>
<code>etcd</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.EtcdSpec">
EtcdSpec
</a>
</em>
</td>
<td>
<p>Etcd specifies configuration for the control plane etcd cluster. The
default ManagementType is Managed. Once set, the ManagementType cannot be
changed.</p>
</td>
</tr>
<tr>
<td>
<code>services</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.ServicePublishingStrategyMapping">
[]ServicePublishingStrategyMapping
</a>
</em>
</td>
<td>
<p>Services specifies how individual control plane services are published from
the hosting cluster of the control plane.</p>
<p>If a given service is not present in this list, it will be exposed publicly
by default.</p>
</td>
</tr>
<tr>
<td>
<code>pullSecret</code></br>
<em>
<a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.22/#localobjectreference-v1-core">
Kubernetes core/v1.LocalObjectReference
</a>
</em>
</td>
<td>
<p>PullSecret references a pull secret to be injected into the container
runtime of all cluster nodes. The secret must have a key named
&ldquo;.dockerconfigjson&rdquo; whose value is the pull secret JSON.</p>
</td>
</tr>
<tr>
<td>
<code>sshKey</code></br>
<em>
<a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.22/#localobjectreference-v1-core">
Kubernetes core/v1.LocalObjectReference
</a>
</em>
</td>
<td>
<p>SSHKey references an SSH key to be injected into all cluster node sshd
servers. The secret must have a single key &ldquo;id_rsa.pub&rdquo; whose value is the
public part of an SSH key.</p>
</td>
</tr>
<tr>
<td>
<code>issuerURL</code></br>
<em>
string
</em>
</td>
<td>
<em>(Optional)</em>
<p>IssuerURL is an OIDC issuer URL which is used as the issuer in all
ServiceAccount tokens generated by the control plane API server. The
default value is kubernetes.default.svc, which only works for in-cluster
validation.</p>
</td>
</tr>
<tr>
<td>
<code>serviceAccountSigningKey</code></br>
<em>
<a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.22/#localobjectreference-v1-core">
Kubernetes core/v1.LocalObjectReference
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>ServiceAccountSigningKey is a reference to a secret containing the private key
used by the service account token issuer. The secret is expected to contain
a single key named &ldquo;key&rdquo;. If not specified, a service account signing key will
be generated automatically for the cluster. When specifying a service account
signing key, a IssuerURL must also be specified.</p>
</td>
</tr>
<tr>
<td>
<code>configuration</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.ClusterConfiguration">
ClusterConfiguration
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>Configuration specifies configuration for individual OCP components in the
cluster, represented as embedded resources that correspond to the openshift
configuration API.</p>
</td>
</tr>
<tr>
<td>
<code>auditWebhook</code></br>
<em>
<a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.22/#localobjectreference-v1-core">
Kubernetes core/v1.LocalObjectReference
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>AuditWebhook contains metadata for configuring an audit webhook endpoint
for a cluster to process cluster audit events. It references a secret that
contains the webhook information for the audit webhook endpoint. It is a
secret because if the endpoint has mTLS the kubeconfig will contain client
keys. The kubeconfig needs to be stored in the secret with a secret key
name that corresponds to the constant AuditWebhookKubeconfigKey.</p>
<p>This field is currently only supported on the IBMCloud platform.</p>
</td>
</tr>
<tr>
<td>
<code>imageContentSources</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.ImageContentSource">
[]ImageContentSource
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>ImageContentSources specifies image mirrors that can be used by cluster
nodes to pull content.</p>
</td>
</tr>
<tr>
<td>
<code>additionalTrustBundle</code></br>
<em>
<a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.22/#localobjectreference-v1-core">
Kubernetes core/v1.LocalObjectReference
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>AdditionalTrustBundle is a reference to a ConfigMap containing a
PEM-encoded X.509 certificate bundle that will be added to the hosted controlplane and nodes</p>
</td>
</tr>
<tr>
<td>
<code>secretEncryption</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.SecretEncryptionSpec">
SecretEncryptionSpec
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>SecretEncryption specifies a Kubernetes secret encryption strategy for the
control plane.</p>
</td>
</tr>
<tr>
<td>
<code>fips</code></br>
<em>
bool
</em>
</td>
<td>
<em>(Optional)</em>
<p>FIPS indicates whether this cluster&rsquo;s nodes will be running in FIPS mode.
If set to true, the control plane&rsquo;s ignition server will be configured to
expect that nodes joining the cluster will be FIPS-enabled.</p>
</td>
</tr>
<tr>
<td>
<code>pausedUntil</code></br>
<em>
string
</em>
</td>
<td>
<em>(Optional)</em>
<p>PausedUntil is a field that can be used to pause reconciliation on a resource.
Either a date can be provided in RFC3339 format or a boolean. If a date is
provided: reconciliation is paused on the resource until that date. If the boolean true is
provided: reconciliation is paused on the resource until the field is removed.</p>
</td>
</tr>
<tr>
<td>
<code>olmCatalogPlacement</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.OLMCatalogPlacement">
OLMCatalogPlacement
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>OLMCatalogPlacement specifies the placement of OLM catalog components. By default,
this is set to management and OLM catalog components are deployed onto the management
cluster. If set to guest, the OLM catalog components will be deployed onto the guest
cluster.</p>
<p>
Value must be one of:
&#34;guest&#34;, 
&#34;management&#34;
</p>
</td>
</tr>
<tr>
<td>
<code>nodeSelector</code></br>
<em>
map[string]string
</em>
</td>
<td>
<em>(Optional)</em>
<p>NodeSelector when specified, must be true for the pods managed by the HostedCluster to be scheduled.</p>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td>
<code>status</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.HostedClusterStatus">
HostedClusterStatus
</a>
</em>
</td>
<td>
<p>Status is the latest observed status of the HostedCluster.</p>
</td>
</tr>
</tbody>
</table>
##NodePool { #hypershift.openshift.io/v1alpha1.NodePool }
<p>
<p>NodePool is a scalable set of worker nodes attached to a HostedCluster.
NodePool machine architectures are uniform within a given pool, and are
independent of the control planeâ€™s underlying machine architecture.</p>
</p>
<table>
<thead>
<tr>
<th>Field</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<code>apiVersion</code></br>
string</td>
<td>
<code>
hypershift.openshift.io/v1alpha1
</code>
</td>
</tr>
<tr>
<td>
<code>kind</code></br>
string
</td>
<td><code>NodePool</code></td>
</tr>
<tr>
<td>
<code>metadata</code></br>
<em>
<a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.22/#objectmeta-v1-meta">
Kubernetes meta/v1.ObjectMeta
</a>
</em>
</td>
<td>
Refer to the Kubernetes API documentation for the fields of the
<code>metadata</code> field.
</td>
</tr>
<tr>
<td>
<code>spec</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.NodePoolSpec">
NodePoolSpec
</a>
</em>
</td>
<td>
<p>Spec is the desired behavior of the NodePool.</p>
<br/>
<br/>
<table>
<tr>
<td>
<code>clusterName</code></br>
<em>
string
</em>
</td>
<td>
<p>ClusterName is the name of the HostedCluster this NodePool belongs to.</p>
<p>TODO(dan): Should this be a LocalObjectReference?</p>
</td>
</tr>
<tr>
<td>
<code>release</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.Release">
Release
</a>
</em>
</td>
<td>
<p>Release specifies the OCP release used for the NodePool. This informs the
ignition configuration for machines, as well as other platform specific
machine properties (e.g. an AMI on the AWS platform).</p>
</td>
</tr>
<tr>
<td>
<code>platform</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.NodePoolPlatform">
NodePoolPlatform
</a>
</em>
</td>
<td>
<p>Platform specifies the underlying infrastructure provider for the NodePool
and is used to configure platform specific behavior.</p>
</td>
</tr>
<tr>
<td>
<code>nodeCount</code></br>
<em>
int32
</em>
</td>
<td>
<em>(Optional)</em>
<p>Deprecated: Use Replicas instead. NodeCount will be dropped in the next
api release.</p>
</td>
</tr>
<tr>
<td>
<code>replicas</code></br>
<em>
int32
</em>
</td>
<td>
<em>(Optional)</em>
<p>Replicas is the desired number of nodes the pool should maintain. If
unset, the default value is 0.</p>
</td>
</tr>
<tr>
<td>
<code>management</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.NodePoolManagement">
NodePoolManagement
</a>
</em>
</td>
<td>
<p>Management specifies behavior for managing nodes in the pool, such as
upgrade strategies and auto-repair behaviors.</p>
</td>
</tr>
<tr>
<td>
<code>autoScaling</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.NodePoolAutoScaling">
NodePoolAutoScaling
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>Autoscaling specifies auto-scaling behavior for the NodePool.</p>
</td>
</tr>
<tr>
<td>
<code>config</code></br>
<em>
<a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.22/#localobjectreference-v1-core">
[]Kubernetes core/v1.LocalObjectReference
</a>
</em>
</td>
<td>
<p>Config is a list of references to ConfigMaps containing serialized
MachineConfig resources to be injected into the ignition configurations of
nodes in the NodePool. The MachineConfig API schema is defined here:</p>
<p><a href="https://github.com/openshift/machine-config-operator/blob/18963e4f8fe66e8c513ca4b131620760a414997f/pkg/apis/machineconfiguration.openshift.io/v1/types.go#L185">https://github.com/openshift/machine-config-operator/blob/18963e4f8fe66e8c513ca4b131620760a414997f/pkg/apis/machineconfiguration.openshift.io/v1/types.go#L185</a></p>
<p>Each ConfigMap must have a single key named &ldquo;config&rdquo; whose value is the
JSON or YAML of a serialized MachineConfig.</p>
</td>
</tr>
<tr>
<td>
<code>nodeDrainTimeout</code></br>
<em>
<a href="https://godoc.org/k8s.io/apimachinery/pkg/apis/meta/v1#Duration">
Kubernetes meta/v1.Duration
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>NodeDrainTimeout is the total amount of time that the controller will spend on draining a node.
The default value is 0, meaning that the node can be drained without any time limitations.
NOTE: NodeDrainTimeout is different from <code>kubectl drain --timeout</code>
TODO (alberto): Today changing this field will trigger a recreate rolling update, which kind of defeats
the purpose of the change. In future we plan to propagate this field in-place.
<a href="https://github.com/kubernetes-sigs/cluster-api/issues/5880">https://github.com/kubernetes-sigs/cluster-api/issues/5880</a></p>
</td>
</tr>
<tr>
<td>
<code>pausedUntil</code></br>
<em>
string
</em>
</td>
<td>
<em>(Optional)</em>
<p>PausedUntil is a field that can be used to pause reconciliation on a resource.
Either a date can be provided in RFC3339 format or a boolean. If a date is
provided: reconciliation is paused on the resource until that date. If the boolean true is
provided: reconciliation is paused on the resource until the field is removed.</p>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td>
<code>status</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.NodePoolStatus">
NodePoolStatus
</a>
</em>
</td>
<td>
<p>Status is the latest observed status of the NodePool.</p>
</td>
</tr>
</tbody>
</table>
###AESCBCSpec { #hypershift.openshift.io/v1alpha1.AESCBCSpec }
<p>
(<em>Appears on:</em>
<a href="#hypershift.openshift.io/v1alpha1.SecretEncryptionSpec">SecretEncryptionSpec</a>)
</p>
<p>
<p>AESCBCSpec defines metadata about the AESCBC secret encryption strategy</p>
</p>
<table>
<thead>
<tr>
<th>Field</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<code>activeKey</code></br>
<em>
<a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.22/#localobjectreference-v1-core">
Kubernetes core/v1.LocalObjectReference
</a>
</em>
</td>
<td>
<p>ActiveKey defines the active key used to encrypt new secrets</p>
</td>
</tr>
<tr>
<td>
<code>backupKey</code></br>
<em>
<a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.22/#localobjectreference-v1-core">
Kubernetes core/v1.LocalObjectReference
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>BackupKey defines the old key during the rotation process so previously created
secrets can continue to be decrypted until they are all re-encrypted with the active key.</p>
</td>
</tr>
</tbody>
</table>
###APIServerNetworking { #hypershift.openshift.io/v1alpha1.APIServerNetworking }
<p>
(<em>Appears on:</em>
<a href="#hypershift.openshift.io/v1alpha1.ClusterNetworking">ClusterNetworking</a>)
</p>
<p>
<p>APIServerNetworking specifies how the APIServer is exposed inside a cluster
node.</p>
</p>
<table>
<thead>
<tr>
<th>Field</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<code>advertiseAddress</code></br>
<em>
string
</em>
</td>
<td>
<p>AdvertiseAddress is the address that nodes will use to talk to the API
server. This is an address associated with the loopback adapter of each
node. If not specified, 172.20.0.1 is used.</p>
</td>
</tr>
<tr>
<td>
<code>port</code></br>
<em>
int32
</em>
</td>
<td>
<p>Port is the port at which the APIServer is exposed inside a node. Other
pods using host networking cannot listen on this port. If not specified,
6443 is used.</p>
</td>
</tr>
<tr>
<td>
<code>allowedCIDRBlocks</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.CIDRBlock">
[]CIDRBlock
</a>
</em>
</td>
<td>
<p>AllowedCIDRBlocks is an allow list of CIDR blocks that can access the APIServer
If not specified, traffic is allowed from all addresses.
This depends on underlying support by the cloud provider for Service LoadBalancerSourceRanges</p>
</td>
</tr>
</tbody>
</table>
###AWSCloudProviderConfig { #hypershift.openshift.io/v1alpha1.AWSCloudProviderConfig }
<p>
(<em>Appears on:</em>
<a href="#hypershift.openshift.io/v1alpha1.AWSPlatformSpec">AWSPlatformSpec</a>)
</p>
<p>
<p>AWSCloudProviderConfig specifies AWS networking configuration.</p>
</p>
<table>
<thead>
<tr>
<th>Field</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<code>subnet</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.AWSResourceReference">
AWSResourceReference
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>Subnet is the subnet to use for control plane cloud resources.</p>
</td>
</tr>
<tr>
<td>
<code>zone</code></br>
<em>
string
</em>
</td>
<td>
<em>(Optional)</em>
<p>Zone is the availability zone where control plane cloud resources are
created.</p>
</td>
</tr>
<tr>
<td>
<code>vpc</code></br>
<em>
string
</em>
</td>
<td>
<p>VPC is the VPC to use for control plane cloud resources.</p>
</td>
</tr>
</tbody>
</table>
###AWSEndpointAccessType { #hypershift.openshift.io/v1alpha1.AWSEndpointAccessType }
<p>
(<em>Appears on:</em>
<a href="#hypershift.openshift.io/v1alpha1.AWSPlatformSpec">AWSPlatformSpec</a>)
</p>
<p>
<p>AWSEndpointAccessType specifies the publishing scope of cluster endpoints.</p>
</p>
<table>
<thead>
<tr>
<th>Value</th>
<th>Description</th>
</tr>
</thead>
<tbody><tr><td><p>&#34;Private&#34;</p></td>
<td><p>Private endpoint access allows only private API server access and private
node communication with the control plane.</p>
</td>
</tr><tr><td><p>&#34;Public&#34;</p></td>
<td><p>Public endpoint access allows public API server access and public node
communication with the control plane.</p>
</td>
</tr><tr><td><p>&#34;PublicAndPrivate&#34;</p></td>
<td><p>PublicAndPrivate endpoint access allows public API server access and
private node communication with the control plane.</p>
</td>
</tr></tbody>
</table>
###AWSKMSAuthSpec { #hypershift.openshift.io/v1alpha1.AWSKMSAuthSpec }
<p>
(<em>Appears on:</em>
<a href="#hypershift.openshift.io/v1alpha1.AWSKMSSpec">AWSKMSSpec</a>)
</p>
<p>
<p>AWSKMSAuthSpec defines metadata about the management of credentials used to interact with AWS KMS</p>
</p>
<table>
<thead>
<tr>
<th>Field</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<code>credentials</code></br>
<em>
<a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.22/#localobjectreference-v1-core">
Kubernetes core/v1.LocalObjectReference
</a>
</em>
</td>
<td>
<p>Credentials contains the name of the secret that holds the aws credentials that can be used
to make the necessary KMS calls. It should at key AWSCredentialsFileSecretKey contain the
aws credentials file that can be used to configure AWS SDKs</p>
</td>
</tr>
</tbody>
</table>
###AWSKMSKeyEntry { #hypershift.openshift.io/v1alpha1.AWSKMSKeyEntry }
<p>
(<em>Appears on:</em>
<a href="#hypershift.openshift.io/v1alpha1.AWSKMSSpec">AWSKMSSpec</a>)
</p>
<p>
<p>AWSKMSKeyEntry defines metadata to locate the encryption key in AWS</p>
</p>
<table>
<thead>
<tr>
<th>Field</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<code>arn</code></br>
<em>
string
</em>
</td>
<td>
<p>ARN is the Amazon Resource Name for the encryption key</p>
</td>
</tr>
</tbody>
</table>
###AWSKMSSpec { #hypershift.openshift.io/v1alpha1.AWSKMSSpec }
<p>
(<em>Appears on:</em>
<a href="#hypershift.openshift.io/v1alpha1.KMSSpec">KMSSpec</a>)
</p>
<p>
<p>AWSKMSSpec defines metadata about the configuration of the AWS KMS Secret Encryption provider</p>
</p>
<table>
<thead>
<tr>
<th>Field</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<code>region</code></br>
<em>
string
</em>
</td>
<td>
<p>Region contains the AWS region</p>
</td>
</tr>
<tr>
<td>
<code>activeKey</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.AWSKMSKeyEntry">
AWSKMSKeyEntry
</a>
</em>
</td>
<td>
<p>ActiveKey defines the active key used to encrypt new secrets</p>
</td>
</tr>
<tr>
<td>
<code>backupKey</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.AWSKMSKeyEntry">
AWSKMSKeyEntry
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>BackupKey defines the old key during the rotation process so previously created
secrets can continue to be decrypted until they are all re-encrypted with the active key.</p>
</td>
</tr>
<tr>
<td>
<code>auth</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.AWSKMSAuthSpec">
AWSKMSAuthSpec
</a>
</em>
</td>
<td>
<p>Auth defines metadata about the management of credentials used to interact with AWS KMS</p>
</td>
</tr>
</tbody>
</table>
###AWSNodePoolPlatform { #hypershift.openshift.io/v1alpha1.AWSNodePoolPlatform }
<p>
(<em>Appears on:</em>
<a href="#hypershift.openshift.io/v1alpha1.NodePoolPlatform">NodePoolPlatform</a>)
</p>
<p>
<p>AWSNodePoolPlatform specifies the configuration of a NodePool when operating
on AWS.</p>
</p>
<table>
<thead>
<tr>
<th>Field</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<code>instanceType</code></br>
<em>
string
</em>
</td>
<td>
<p>InstanceType is an ec2 instance type for node instances (e.g. m5.large).</p>
</td>
</tr>
<tr>
<td>
<code>instanceProfile</code></br>
<em>
string
</em>
</td>
<td>
<p>InstanceProfile is the AWS EC2 instance profile, which is a container for an IAM role that the EC2 instance uses.</p>
</td>
</tr>
<tr>
<td>
<code>subnet</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.AWSResourceReference">
AWSResourceReference
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>Subnet is the subnet to use for node instances.</p>
</td>
</tr>
<tr>
<td>
<code>ami</code></br>
<em>
string
</em>
</td>
<td>
<em>(Optional)</em>
<p>AMI is the image id to use for node instances. If unspecified, the default
is chosen based on the NodePool release payload image.</p>
</td>
</tr>
<tr>
<td>
<code>securityGroups</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.AWSResourceReference">
[]AWSResourceReference
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>SecurityGroups is an optional set of security groups to associate with node
instances.</p>
</td>
</tr>
<tr>
<td>
<code>rootVolume</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.Volume">
Volume
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>RootVolume specifies configuration for the root volume of node instances.</p>
</td>
</tr>
<tr>
<td>
<code>resourceTags</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.AWSResourceTag">
[]AWSResourceTag
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>ResourceTags is an optional list of additional tags to apply to AWS node
instances.</p>
<p>These will be merged with HostedCluster scoped tags, and HostedCluster tags
take precedence in case of conflicts.</p>
<p>See <a href="https://docs.aws.amazon.com/general/latest/gr/aws_tagging.html">https://docs.aws.amazon.com/general/latest/gr/aws_tagging.html</a> for
information on tagging AWS resources. AWS supports a maximum of 50 tags per
resource. OpenShift reserves 25 tags for its use, leaving 25 tags available
for the user.</p>
</td>
</tr>
</tbody>
</table>
###AWSPlatformSpec { #hypershift.openshift.io/v1alpha1.AWSPlatformSpec }
<p>
(<em>Appears on:</em>
<a href="#hypershift.openshift.io/v1alpha1.PlatformSpec">PlatformSpec</a>)
</p>
<p>
<p>AWSPlatformSpec specifies configuration for clusters running on Amazon Web Services.</p>
</p>
<table>
<thead>
<tr>
<th>Field</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<code>region</code></br>
<em>
string
</em>
</td>
<td>
<p>Region is the AWS region in which the cluster resides. This configures the
OCP control plane cloud integrations, and is used by NodePool to resolve
the correct boot AMI for a given release.</p>
</td>
</tr>
<tr>
<td>
<code>cloudProviderConfig</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.AWSCloudProviderConfig">
AWSCloudProviderConfig
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>CloudProviderConfig specifies AWS networking configuration for the control
plane.
This is mainly used for cloud provider controller config:
<a href="https://github.com/kubernetes/kubernetes/blob/f5be5052e3d0808abb904aebd3218fe4a5c2dd82/staging/src/k8s.io/legacy-cloud-providers/aws/aws.go#L1347-L1364">https://github.com/kubernetes/kubernetes/blob/f5be5052e3d0808abb904aebd3218fe4a5c2dd82/staging/src/k8s.io/legacy-cloud-providers/aws/aws.go#L1347-L1364</a>
TODO(dan): should this be named AWSNetworkConfig?</p>
</td>
</tr>
<tr>
<td>
<code>serviceEndpoints</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.AWSServiceEndpoint">
[]AWSServiceEndpoint
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>ServiceEndpoints specifies optional custom endpoints which will override
the default service endpoint of specific AWS Services.</p>
<p>There must be only one ServiceEndpoint for a given service name.</p>
</td>
</tr>
<tr>
<td>
<code>rolesRef</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.AWSRolesRef">
AWSRolesRef
</a>
</em>
</td>
<td>
<p>RolesRef contains references to various AWS IAM roles required to enable
integrations such as OIDC.</p>
</td>
</tr>
<tr>
<td>
<code>roles</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.AWSRoleCredentials">
[]AWSRoleCredentials
</a>
</em>
</td>
<td>
<p>Deprecated
This field will be removed in the next API release.
Use RolesRef instead.</p>
</td>
</tr>
<tr>
<td>
<code>kubeCloudControllerCreds</code></br>
<em>
<a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.22/#localobjectreference-v1-core">
Kubernetes core/v1.LocalObjectReference
</a>
</em>
</td>
<td>
<p>Deprecated
This field will be removed in the next API release.
Use RolesRef instead.</p>
</td>
</tr>
<tr>
<td>
<code>nodePoolManagementCreds</code></br>
<em>
<a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.22/#localobjectreference-v1-core">
Kubernetes core/v1.LocalObjectReference
</a>
</em>
</td>
<td>
<p>Deprecated
This field will be removed in the next API release.
Use RolesRef instead.</p>
</td>
</tr>
<tr>
<td>
<code>controlPlaneOperatorCreds</code></br>
<em>
<a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.22/#localobjectreference-v1-core">
Kubernetes core/v1.LocalObjectReference
</a>
</em>
</td>
<td>
<p>Deprecated
This field will be removed in the next API release.
Use RolesRef instead.</p>
</td>
</tr>
<tr>
<td>
<code>resourceTags</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.AWSResourceTag">
[]AWSResourceTag
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>ResourceTags is a list of additional tags to apply to AWS resources created
for the cluster. See
<a href="https://docs.aws.amazon.com/general/latest/gr/aws_tagging.html">https://docs.aws.amazon.com/general/latest/gr/aws_tagging.html</a> for
information on tagging AWS resources. AWS supports a maximum of 50 tags per
resource. OpenShift reserves 25 tags for its use, leaving 25 tags available
for the user.</p>
</td>
</tr>
<tr>
<td>
<code>endpointAccess</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.AWSEndpointAccessType">
AWSEndpointAccessType
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>EndpointAccess specifies the publishing scope of cluster endpoints. The
default is Public.</p>
<p>
Value must be one of:
&#34;Private&#34;, 
&#34;Public&#34;, 
&#34;PublicAndPrivate&#34;
</p>
</td>
</tr>
</tbody>
</table>
###AWSResourceReference { #hypershift.openshift.io/v1alpha1.AWSResourceReference }
<p>
(<em>Appears on:</em>
<a href="#hypershift.openshift.io/v1alpha1.AWSCloudProviderConfig">AWSCloudProviderConfig</a>, 
<a href="#hypershift.openshift.io/v1alpha1.AWSNodePoolPlatform">AWSNodePoolPlatform</a>)
</p>
<p>
<p>AWSResourceReference is a reference to a specific AWS resource by ID, ARN, or filters.
Only one of ID, ARN or Filters may be specified. Specifying more than one will result in
a validation error.</p>
</p>
<table>
<thead>
<tr>
<th>Field</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<code>id</code></br>
<em>
string
</em>
</td>
<td>
<em>(Optional)</em>
<p>ID of resource</p>
</td>
</tr>
<tr>
<td>
<code>arn</code></br>
<em>
string
</em>
</td>
<td>
<em>(Optional)</em>
<p>ARN of resource</p>
</td>
</tr>
<tr>
<td>
<code>filters</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.Filter">
[]Filter
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>Filters is a set of key/value pairs used to identify a resource
They are applied according to the rules defined by the AWS API:
<a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/Using_Filtering.html">https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/Using_Filtering.html</a></p>
</td>
</tr>
</tbody>
</table>
###AWSResourceTag { #hypershift.openshift.io/v1alpha1.AWSResourceTag }
<p>
(<em>Appears on:</em>
<a href="#hypershift.openshift.io/v1alpha1.AWSNodePoolPlatform">AWSNodePoolPlatform</a>, 
<a href="#hypershift.openshift.io/v1alpha1.AWSPlatformSpec">AWSPlatformSpec</a>)
</p>
<p>
<p>AWSResourceTag is a tag to apply to AWS resources created for the cluster.</p>
</p>
<table>
<thead>
<tr>
<th>Field</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<code>key</code></br>
<em>
string
</em>
</td>
<td>
<p>Key is the key of the tag.</p>
</td>
</tr>
<tr>
<td>
<code>value</code></br>
<em>
string
</em>
</td>
<td>
<p>Value is the value of the tag.</p>
<p>Some AWS service do not support empty values. Since tags are added to
resources in many services, the length of the tag value must meet the
requirements of all services.</p>
</td>
</tr>
</tbody>
</table>
###AWSRoleCredentials { #hypershift.openshift.io/v1alpha1.AWSRoleCredentials }
<p>
(<em>Appears on:</em>
<a href="#hypershift.openshift.io/v1alpha1.AWSPlatformSpec">AWSPlatformSpec</a>)
</p>
<p>
</p>
<table>
<thead>
<tr>
<th>Field</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<code>arn</code></br>
<em>
string
</em>
</td>
<td>
</td>
</tr>
<tr>
<td>
<code>namespace</code></br>
<em>
string
</em>
</td>
<td>
</td>
</tr>
<tr>
<td>
<code>name</code></br>
<em>
string
</em>
</td>
<td>
</td>
</tr>
</tbody>
</table>
###AWSRolesRef { #hypershift.openshift.io/v1alpha1.AWSRolesRef }
<p>
(<em>Appears on:</em>
<a href="#hypershift.openshift.io/v1alpha1.AWSPlatformSpec">AWSPlatformSpec</a>)
</p>
<p>
<p>AWSRolesRef contains references to various AWS IAM roles required for operators to make calls against the AWS API.</p>
</p>
<table>
<thead>
<tr>
<th>Field</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<code>ingressARN</code></br>
<em>
string
</em>
</td>
<td>
<p>The referenced role must have a trust relationship that allows it to be assumed via web identity.
<a href="https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_providers_oidc.html">https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_providers_oidc.html</a>.
Example:
{
&ldquo;Version&rdquo;: &ldquo;2012-10-17&rdquo;,
&ldquo;Statement&rdquo;: [
{
&ldquo;Effect&rdquo;: &ldquo;Allow&rdquo;,
&ldquo;Principal&rdquo;: {
&ldquo;Federated&rdquo;: &ldquo;{{ .ProviderARN }}&rdquo;
},
&ldquo;Action&rdquo;: &ldquo;sts:AssumeRoleWithWebIdentity&rdquo;,
&ldquo;Condition&rdquo;: {
&ldquo;StringEquals&rdquo;: {
&ldquo;{{ .ProviderName }}:sub&rdquo;: {{ .ServiceAccounts }}
}
}
}
]
}</p>
<p>IngressARN is an ARN value referencing a role appropriate for the Ingress Operator.</p>
<p>The following is an example of a valid policy document:</p>
<p>{
&ldquo;Version&rdquo;: &ldquo;2012-10-17&rdquo;,
&ldquo;Statement&rdquo;: [
{
&ldquo;Effect&rdquo;: &ldquo;Allow&rdquo;,
&ldquo;Action&rdquo;: [
&ldquo;elasticloadbalancing:DescribeLoadBalancers&rdquo;,
&ldquo;tag:GetResources&rdquo;,
&ldquo;route53:ListHostedZones&rdquo;
],
&ldquo;Resource&rdquo;: &ldquo;*&rdquo;
},
{
&ldquo;Effect&rdquo;: &ldquo;Allow&rdquo;,
&ldquo;Action&rdquo;: [
&ldquo;route53:ChangeResourceRecordSets&rdquo;
],
&ldquo;Resource&rdquo;: [
&ldquo;arn:aws:route53:::PUBLIC_ZONE_ID&rdquo;,
&ldquo;arn:aws:route53:::PRIVATE_ZONE_ID&rdquo;
]
}
]
}</p>
</td>
</tr>
<tr>
<td>
<code>imageRegistryARN</code></br>
<em>
string
</em>
</td>
<td>
<p>ImageRegistryARN is an ARN value referencing a role appropriate for the Image Registry Operator.</p>
<p>The following is an example of a valid policy document:</p>
<p>{
&ldquo;Version&rdquo;: &ldquo;2012-10-17&rdquo;,
&ldquo;Statement&rdquo;: [
{
&ldquo;Effect&rdquo;: &ldquo;Allow&rdquo;,
&ldquo;Action&rdquo;: [
&ldquo;s3:CreateBucket&rdquo;,
&ldquo;s3:DeleteBucket&rdquo;,
&ldquo;s3:PutBucketTagging&rdquo;,
&ldquo;s3:GetBucketTagging&rdquo;,
&ldquo;s3:PutBucketPublicAccessBlock&rdquo;,
&ldquo;s3:GetBucketPublicAccessBlock&rdquo;,
&ldquo;s3:PutEncryptionConfiguration&rdquo;,
&ldquo;s3:GetEncryptionConfiguration&rdquo;,
&ldquo;s3:PutLifecycleConfiguration&rdquo;,
&ldquo;s3:GetLifecycleConfiguration&rdquo;,
&ldquo;s3:GetBucketLocation&rdquo;,
&ldquo;s3:ListBucket&rdquo;,
&ldquo;s3:GetObject&rdquo;,
&ldquo;s3:PutObject&rdquo;,
&ldquo;s3:DeleteObject&rdquo;,
&ldquo;s3:ListBucketMultipartUploads&rdquo;,
&ldquo;s3:AbortMultipartUpload&rdquo;,
&ldquo;s3:ListMultipartUploadParts&rdquo;
],
&ldquo;Resource&rdquo;: &ldquo;*&rdquo;
}
]
}</p>
</td>
</tr>
<tr>
<td>
<code>storageARN</code></br>
<em>
string
</em>
</td>
<td>
<p>StorageARN is an ARN value referencing a role appropriate for the Storage Operator.</p>
<p>The following is an example of a valid policy document:</p>
<p>{
&ldquo;Version&rdquo;: &ldquo;2012-10-17&rdquo;,
&ldquo;Statement&rdquo;: [
{
&ldquo;Effect&rdquo;: &ldquo;Allow&rdquo;,
&ldquo;Action&rdquo;: [
&ldquo;ec2:AttachVolume&rdquo;,
&ldquo;ec2:CreateSnapshot&rdquo;,
&ldquo;ec2:CreateTags&rdquo;,
&ldquo;ec2:CreateVolume&rdquo;,
&ldquo;ec2:DeleteSnapshot&rdquo;,
&ldquo;ec2:DeleteTags&rdquo;,
&ldquo;ec2:DeleteVolume&rdquo;,
&ldquo;ec2:DescribeInstances&rdquo;,
&ldquo;ec2:DescribeSnapshots&rdquo;,
&ldquo;ec2:DescribeTags&rdquo;,
&ldquo;ec2:DescribeVolumes&rdquo;,
&ldquo;ec2:DescribeVolumesModifications&rdquo;,
&ldquo;ec2:DetachVolume&rdquo;,
&ldquo;ec2:ModifyVolume&rdquo;
],
&ldquo;Resource&rdquo;: &ldquo;*&rdquo;
}
]
}</p>
</td>
</tr>
<tr>
<td>
<code>networkARN</code></br>
<em>
string
</em>
</td>
<td>
<p>NetworkARN is an ARN value referencing a role appropriate for the Network Operator.</p>
<p>The following is an example of a valid policy document:</p>
<p>{
&ldquo;Version&rdquo;: &ldquo;2012-10-17&rdquo;,
&ldquo;Statement&rdquo;: [
{
&ldquo;Effect&rdquo;: &ldquo;Allow&rdquo;,
&ldquo;Action&rdquo;: [
&ldquo;ec2:DescribeInstances&rdquo;,
&ldquo;ec2:DescribeInstanceStatus&rdquo;,
&ldquo;ec2:DescribeInstanceTypes&rdquo;,
&ldquo;ec2:UnassignPrivateIpAddresses&rdquo;,
&ldquo;ec2:AssignPrivateIpAddresses&rdquo;,
&ldquo;ec2:UnassignIpv6Addresses&rdquo;,
&ldquo;ec2:AssignIpv6Addresses&rdquo;,
&ldquo;ec2:DescribeSubnets&rdquo;,
&ldquo;ec2:DescribeNetworkInterfaces&rdquo;
],
&ldquo;Resource&rdquo;: &ldquo;*&rdquo;
}
]
}</p>
</td>
</tr>
<tr>
<td>
<code>kubeCloudControllerARN</code></br>
<em>
string
</em>
</td>
<td>
<p>KubeCloudControllerARN is an ARN value referencing a role appropriate for the KCM/KCC.</p>
<p>The following is an example of a valid policy document:</p>
<p>{
&ldquo;Version&rdquo;: &ldquo;2012-10-17&rdquo;,
&ldquo;Statement&rdquo;: [
{
&ldquo;Action&rdquo;: [
&ldquo;ec2:DescribeInstances&rdquo;,
&ldquo;ec2:DescribeImages&rdquo;,
&ldquo;ec2:DescribeRegions&rdquo;,
&ldquo;ec2:DescribeRouteTables&rdquo;,
&ldquo;ec2:DescribeSecurityGroups&rdquo;,
&ldquo;ec2:DescribeSubnets&rdquo;,
&ldquo;ec2:DescribeVolumes&rdquo;,
&ldquo;ec2:CreateSecurityGroup&rdquo;,
&ldquo;ec2:CreateTags&rdquo;,
&ldquo;ec2:CreateVolume&rdquo;,
&ldquo;ec2:ModifyInstanceAttribute&rdquo;,
&ldquo;ec2:ModifyVolume&rdquo;,
&ldquo;ec2:AttachVolume&rdquo;,
&ldquo;ec2:AuthorizeSecurityGroupIngress&rdquo;,
&ldquo;ec2:CreateRoute&rdquo;,
&ldquo;ec2:DeleteRoute&rdquo;,
&ldquo;ec2:DeleteSecurityGroup&rdquo;,
&ldquo;ec2:DeleteVolume&rdquo;,
&ldquo;ec2:DetachVolume&rdquo;,
&ldquo;ec2:RevokeSecurityGroupIngress&rdquo;,
&ldquo;ec2:DescribeVpcs&rdquo;,
&ldquo;elasticloadbalancing:AddTags&rdquo;,
&ldquo;elasticloadbalancing:AttachLoadBalancerToSubnets&rdquo;,
&ldquo;elasticloadbalancing:ApplySecurityGroupsToLoadBalancer&rdquo;,
&ldquo;elasticloadbalancing:CreateLoadBalancer&rdquo;,
&ldquo;elasticloadbalancing:CreateLoadBalancerPolicy&rdquo;,
&ldquo;elasticloadbalancing:CreateLoadBalancerListeners&rdquo;,
&ldquo;elasticloadbalancing:ConfigureHealthCheck&rdquo;,
&ldquo;elasticloadbalancing:DeleteLoadBalancer&rdquo;,
&ldquo;elasticloadbalancing:DeleteLoadBalancerListeners&rdquo;,
&ldquo;elasticloadbalancing:DescribeLoadBalancers&rdquo;,
&ldquo;elasticloadbalancing:DescribeLoadBalancerAttributes&rdquo;,
&ldquo;elasticloadbalancing:DetachLoadBalancerFromSubnets&rdquo;,
&ldquo;elasticloadbalancing:DeregisterInstancesFromLoadBalancer&rdquo;,
&ldquo;elasticloadbalancing:ModifyLoadBalancerAttributes&rdquo;,
&ldquo;elasticloadbalancing:RegisterInstancesWithLoadBalancer&rdquo;,
&ldquo;elasticloadbalancing:SetLoadBalancerPoliciesForBackendServer&rdquo;,
&ldquo;elasticloadbalancing:AddTags&rdquo;,
&ldquo;elasticloadbalancing:CreateListener&rdquo;,
&ldquo;elasticloadbalancing:CreateTargetGroup&rdquo;,
&ldquo;elasticloadbalancing:DeleteListener&rdquo;,
&ldquo;elasticloadbalancing:DeleteTargetGroup&rdquo;,
&ldquo;elasticloadbalancing:DescribeListeners&rdquo;,
&ldquo;elasticloadbalancing:DescribeLoadBalancerPolicies&rdquo;,
&ldquo;elasticloadbalancing:DescribeTargetGroups&rdquo;,
&ldquo;elasticloadbalancing:DescribeTargetHealth&rdquo;,
&ldquo;elasticloadbalancing:ModifyListener&rdquo;,
&ldquo;elasticloadbalancing:ModifyTargetGroup&rdquo;,
&ldquo;elasticloadbalancing:RegisterTargets&rdquo;,
&ldquo;elasticloadbalancing:SetLoadBalancerPoliciesOfListener&rdquo;,
&ldquo;iam:CreateServiceLinkedRole&rdquo;,
&ldquo;kms:DescribeKey&rdquo;
],
&ldquo;Resource&rdquo;: [
&ldquo;*&rdquo;
],
&ldquo;Effect&rdquo;: &ldquo;Allow&rdquo;
}
]
}</p>
</td>
</tr>
<tr>
<td>
<code>nodePoolManagementARN</code></br>
<em>
string
</em>
</td>
<td>
<p>NodePoolManagementARN is an ARN value referencing a role appropriate for the CAPI Controller.</p>
<p>The following is an example of a valid policy document:</p>
<p>{
&ldquo;Version&rdquo;: &ldquo;2012-10-17&rdquo;,
&ldquo;Statement&rdquo;: [
{
&ldquo;Action&rdquo;: [
&ldquo;ec2:AllocateAddress&rdquo;,
&ldquo;ec2:AssociateRouteTable&rdquo;,
&ldquo;ec2:AttachInternetGateway&rdquo;,
&ldquo;ec2:AuthorizeSecurityGroupIngress&rdquo;,
&ldquo;ec2:CreateInternetGateway&rdquo;,
&ldquo;ec2:CreateNatGateway&rdquo;,
&ldquo;ec2:CreateRoute&rdquo;,
&ldquo;ec2:CreateRouteTable&rdquo;,
&ldquo;ec2:CreateSecurityGroup&rdquo;,
&ldquo;ec2:CreateSubnet&rdquo;,
&ldquo;ec2:CreateTags&rdquo;,
&ldquo;ec2:DeleteInternetGateway&rdquo;,
&ldquo;ec2:DeleteNatGateway&rdquo;,
&ldquo;ec2:DeleteRouteTable&rdquo;,
&ldquo;ec2:DeleteSecurityGroup&rdquo;,
&ldquo;ec2:DeleteSubnet&rdquo;,
&ldquo;ec2:DeleteTags&rdquo;,
&ldquo;ec2:DescribeAccountAttributes&rdquo;,
&ldquo;ec2:DescribeAddresses&rdquo;,
&ldquo;ec2:DescribeAvailabilityZones&rdquo;,
&ldquo;ec2:DescribeImages&rdquo;,
&ldquo;ec2:DescribeInstances&rdquo;,
&ldquo;ec2:DescribeInternetGateways&rdquo;,
&ldquo;ec2:DescribeNatGateways&rdquo;,
&ldquo;ec2:DescribeNetworkInterfaces&rdquo;,
&ldquo;ec2:DescribeNetworkInterfaceAttribute&rdquo;,
&ldquo;ec2:DescribeRouteTables&rdquo;,
&ldquo;ec2:DescribeSecurityGroups&rdquo;,
&ldquo;ec2:DescribeSubnets&rdquo;,
&ldquo;ec2:DescribeVpcs&rdquo;,
&ldquo;ec2:DescribeVpcAttribute&rdquo;,
&ldquo;ec2:DescribeVolumes&rdquo;,
&ldquo;ec2:DetachInternetGateway&rdquo;,
&ldquo;ec2:DisassociateRouteTable&rdquo;,
&ldquo;ec2:DisassociateAddress&rdquo;,
&ldquo;ec2:ModifyInstanceAttribute&rdquo;,
&ldquo;ec2:ModifyNetworkInterfaceAttribute&rdquo;,
&ldquo;ec2:ModifySubnetAttribute&rdquo;,
&ldquo;ec2:ReleaseAddress&rdquo;,
&ldquo;ec2:RevokeSecurityGroupIngress&rdquo;,
&ldquo;ec2:RunInstances&rdquo;,
&ldquo;ec2:TerminateInstances&rdquo;,
&ldquo;tag:GetResources&rdquo;,
&ldquo;ec2:CreateLaunchTemplate&rdquo;,
&ldquo;ec2:CreateLaunchTemplateVersion&rdquo;,
&ldquo;ec2:DescribeLaunchTemplates&rdquo;,
&ldquo;ec2:DescribeLaunchTemplateVersions&rdquo;,
&ldquo;ec2:DeleteLaunchTemplate&rdquo;,
&ldquo;ec2:DeleteLaunchTemplateVersions&rdquo;
],
&ldquo;Resource&rdquo;: [
&ldquo;<em>&rdquo;
],
&ldquo;Effect&rdquo;: &ldquo;Allow&rdquo;
},
{
&ldquo;Condition&rdquo;: {
&ldquo;StringLike&rdquo;: {
&ldquo;iam:AWSServiceName&rdquo;: &ldquo;elasticloadbalancing.amazonaws.com&rdquo;
}
},
&ldquo;Action&rdquo;: [
&ldquo;iam:CreateServiceLinkedRole&rdquo;
],
&ldquo;Resource&rdquo;: [
&ldquo;arn:</em>:iam::<em>:role/aws-service-role/elasticloadbalancing.amazonaws.com/AWSServiceRoleForElasticLoadBalancing&rdquo;
],
&ldquo;Effect&rdquo;: &ldquo;Allow&rdquo;
},
{
&ldquo;Action&rdquo;: [
&ldquo;iam:PassRole&rdquo;
],
&ldquo;Resource&rdquo;: [
&ldquo;arn:</em>:iam::<em>:role/</em>-worker-role&rdquo;
],
&ldquo;Effect&rdquo;: &ldquo;Allow&rdquo;
}
]
}</p>
</td>
</tr>
<tr>
<td>
<code>controlPlaneOperatorARN</code></br>
<em>
string
</em>
</td>
<td>
<p>ControlPlaneOperatorARN  is an ARN value referencing a role appropriate for the Control Plane Operator.</p>
<p>The following is an example of a valid policy document:</p>
<p>{
&ldquo;Version&rdquo;: &ldquo;2012-10-17&rdquo;,
&ldquo;Statement&rdquo;: [
{
&ldquo;Effect&rdquo;: &ldquo;Allow&rdquo;,
&ldquo;Action&rdquo;: [
&ldquo;ec2:CreateVpcEndpoint&rdquo;,
&ldquo;ec2:DescribeVpcEndpoints&rdquo;,
&ldquo;ec2:ModifyVpcEndpoint&rdquo;,
&ldquo;ec2:DeleteVpcEndpoints&rdquo;,
&ldquo;ec2:CreateTags&rdquo;,
&ldquo;route53:ListHostedZones&rdquo;
],
&ldquo;Resource&rdquo;: &ldquo;*&rdquo;
},
{
&ldquo;Effect&rdquo;: &ldquo;Allow&rdquo;,
&ldquo;Action&rdquo;: [
&ldquo;route53:ChangeResourceRecordSets&rdquo;,
&ldquo;route53:ListResourceRecordSets&rdquo;
],
&ldquo;Resource&rdquo;: &ldquo;arn:aws:route53:::%s&rdquo;
}
]
}</p>
</td>
</tr>
</tbody>
</table>
###AWSServiceEndpoint { #hypershift.openshift.io/v1alpha1.AWSServiceEndpoint }
<p>
(<em>Appears on:</em>
<a href="#hypershift.openshift.io/v1alpha1.AWSPlatformSpec">AWSPlatformSpec</a>)
</p>
<p>
<p>AWSServiceEndpoint stores the configuration for services to
override existing defaults of AWS Services.</p>
</p>
<table>
<thead>
<tr>
<th>Field</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<code>name</code></br>
<em>
string
</em>
</td>
<td>
<p>Name is the name of the AWS service.
This must be provided and cannot be empty.</p>
</td>
</tr>
<tr>
<td>
<code>url</code></br>
<em>
string
</em>
</td>
<td>
<p>URL is fully qualified URI with scheme https, that overrides the default generated
endpoint for a client.
This must be provided and cannot be empty.</p>
</td>
</tr>
</tbody>
</table>
###AgentNodePoolPlatform { #hypershift.openshift.io/v1alpha1.AgentNodePoolPlatform }
<p>
(<em>Appears on:</em>
<a href="#hypershift.openshift.io/v1alpha1.NodePoolPlatform">NodePoolPlatform</a>)
</p>
<p>
<p>AgentNodePoolPlatform specifies the configuration of a NodePool when operating
on the Agent platform.</p>
</p>
<table>
<thead>
<tr>
<th>Field</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<code>agentLabelSelector</code></br>
<em>
<a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.22/#labelselector-v1-meta">
Kubernetes meta/v1.LabelSelector
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>AgentLabelSelector contains labels that must be set on an Agent in order to
be selected for a Machine.</p>
</td>
</tr>
</tbody>
</table>
###AgentPlatformSpec { #hypershift.openshift.io/v1alpha1.AgentPlatformSpec }
<p>
(<em>Appears on:</em>
<a href="#hypershift.openshift.io/v1alpha1.PlatformSpec">PlatformSpec</a>)
</p>
<p>
<p>AgentPlatformSpec specifies configuration for agent-based installations.</p>
</p>
<table>
<thead>
<tr>
<th>Field</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<code>agentNamespace</code></br>
<em>
string
</em>
</td>
<td>
<p>AgentNamespace is the namespace where to search for Agents for this cluster</p>
</td>
</tr>
</tbody>
</table>
###AvailabilityPolicy { #hypershift.openshift.io/v1alpha1.AvailabilityPolicy }
<p>
(<em>Appears on:</em>
<a href="#hypershift.openshift.io/v1alpha1.HostedClusterSpec">HostedClusterSpec</a>, 
<a href="#hypershift.openshift.io/v1alpha1.HostedControlPlaneSpec">HostedControlPlaneSpec</a>)
</p>
<p>
<p>AvailabilityPolicy specifies a high level availability policy for components.</p>
</p>
<table>
<thead>
<tr>
<th>Value</th>
<th>Description</th>
</tr>
</thead>
<tbody><tr><td><p>&#34;HighlyAvailable&#34;</p></td>
<td><p>HighlyAvailable means components should be resilient to problems across
fault boundaries as defined by the component to which the policy is
attached. This usually means running critical workloads with 3 replicas and
with little or no toleration of disruption of the component.</p>
</td>
</tr><tr><td><p>&#34;SingleReplica&#34;</p></td>
<td><p>SingleReplica means components are not expected to be resilient to problems
across most fault boundaries associated with high availability. This
usually means running critical workloads with just 1 replica and with
toleration of full disruption of the component.</p>
</td>
</tr></tbody>
</table>
###AzureNodePoolPlatform { #hypershift.openshift.io/v1alpha1.AzureNodePoolPlatform }
<p>
(<em>Appears on:</em>
<a href="#hypershift.openshift.io/v1alpha1.NodePoolPlatform">NodePoolPlatform</a>)
</p>
<p>
</p>
<table>
<thead>
<tr>
<th>Field</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<code>vmsize</code></br>
<em>
string
</em>
</td>
<td>
</td>
</tr>
<tr>
<td>
<code>imageID</code></br>
<em>
string
</em>
</td>
<td>
<em>(Optional)</em>
<p>ImageID is the id of the image to boot from. If unset, the default image at the location below will be used:
subscription/$subscriptionID/resourceGroups/$resourceGroupName/providers/Microsoft.Compute/images/rhcos.x86_64.vhd</p>
</td>
</tr>
<tr>
<td>
<code>diskSizeGB</code></br>
<em>
int32
</em>
</td>
<td>
<em>(Optional)</em>
</td>
</tr>
<tr>
<td>
<code>diskStorageAccountType</code></br>
<em>
string
</em>
</td>
<td>
<em>(Optional)</em>
<p>DiskStorageAccountType is the disk storage account type to use. Valid values are:
* Standard_LRS: HDD
* StandardSSD_LRS: Standard SSD
* Premium_LRS: Premium SDD
* UltraSSD_LRS: Ultra SDD</p>
<p>Defaults to Premium_LRS. For more details, visit the Azure documentation:
<a href="https://docs.microsoft.com/en-us/azure/virtual-machines/disks-types#disk-type-comparison">https://docs.microsoft.com/en-us/azure/virtual-machines/disks-types#disk-type-comparison</a></p>
</td>
</tr>
<tr>
<td>
<code>availabilityZone</code></br>
<em>
string
</em>
</td>
<td>
<em>(Optional)</em>
<p>AvailabilityZone of the nodepool. Must not be specified for clusters
in a location that does not support AvailabilityZone.</p>
</td>
</tr>
</tbody>
</table>
###AzurePlatformSpec { #hypershift.openshift.io/v1alpha1.AzurePlatformSpec }
<p>
(<em>Appears on:</em>
<a href="#hypershift.openshift.io/v1alpha1.PlatformSpec">PlatformSpec</a>)
</p>
<p>
</p>
<table>
<thead>
<tr>
<th>Field</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<code>credentials</code></br>
<em>
<a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.22/#localobjectreference-v1-core">
Kubernetes core/v1.LocalObjectReference
</a>
</em>
</td>
<td>
</td>
</tr>
<tr>
<td>
<code>location</code></br>
<em>
string
</em>
</td>
<td>
</td>
</tr>
<tr>
<td>
<code>resourceGroup</code></br>
<em>
string
</em>
</td>
<td>
</td>
</tr>
<tr>
<td>
<code>vnetName</code></br>
<em>
string
</em>
</td>
<td>
</td>
</tr>
<tr>
<td>
<code>vnetID</code></br>
<em>
string
</em>
</td>
<td>
</td>
</tr>
<tr>
<td>
<code>subnetName</code></br>
<em>
string
</em>
</td>
<td>
</td>
</tr>
<tr>
<td>
<code>subscriptionID</code></br>
<em>
string
</em>
</td>
<td>
</td>
</tr>
<tr>
<td>
<code>machineIdentityID</code></br>
<em>
string
</em>
</td>
<td>
</td>
</tr>
<tr>
<td>
<code>securityGroupName</code></br>
<em>
string
</em>
</td>
<td>
</td>
</tr>
</tbody>
</table>
###CIDRBlock { #hypershift.openshift.io/v1alpha1.CIDRBlock }
<p>
(<em>Appears on:</em>
<a href="#hypershift.openshift.io/v1alpha1.APIServerNetworking">APIServerNetworking</a>, 
<a href="#hypershift.openshift.io/v1alpha1.HostedControlPlaneSpec">HostedControlPlaneSpec</a>)
</p>
<p>
</p>
###ClusterAutoscaling { #hypershift.openshift.io/v1alpha1.ClusterAutoscaling }
<p>
(<em>Appears on:</em>
<a href="#hypershift.openshift.io/v1alpha1.HostedClusterSpec">HostedClusterSpec</a>, 
<a href="#hypershift.openshift.io/v1alpha1.HostedControlPlaneSpec">HostedControlPlaneSpec</a>)
</p>
<p>
<p>ClusterAutoscaling specifies auto-scaling behavior that applies to all
NodePools associated with a control plane.</p>
</p>
<table>
<thead>
<tr>
<th>Field</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<code>maxNodesTotal</code></br>
<em>
int32
</em>
</td>
<td>
<p>MaxNodesTotal is the maximum allowable number of nodes across all NodePools
for a HostedCluster. The autoscaler will not grow the cluster beyond this
number.</p>
</td>
</tr>
<tr>
<td>
<code>maxPodGracePeriod</code></br>
<em>
int32
</em>
</td>
<td>
<p>MaxPodGracePeriod is the maximum seconds to wait for graceful pod
termination before scaling down a NodePool. The default is 600 seconds.</p>
</td>
</tr>
<tr>
<td>
<code>maxNodeProvisionTime</code></br>
<em>
string
</em>
</td>
<td>
<p>MaxNodeProvisionTime is the maximum time to wait for node provisioning
before considering the provisioning to be unsuccessful, expressed as a Go
duration string. The default is 15 minutes.</p>
</td>
</tr>
<tr>
<td>
<code>podPriorityThreshold</code></br>
<em>
int32
</em>
</td>
<td>
<em>(Optional)</em>
<p>PodPriorityThreshold enables users to schedule &ldquo;best-effort&rdquo; pods, which
shouldn&rsquo;t trigger autoscaler actions, but only run when there are spare
resources available. The default is -10.</p>
<p>See the following for more details:
<a href="https://github.com/kubernetes/autoscaler/blob/master/cluster-autoscaler/FAQ.md#how-does-cluster-autoscaler-work-with-pod-priority-and-preemption">https://github.com/kubernetes/autoscaler/blob/master/cluster-autoscaler/FAQ.md#how-does-cluster-autoscaler-work-with-pod-priority-and-preemption</a></p>
</td>
</tr>
</tbody>
</table>
###ClusterConfiguration { #hypershift.openshift.io/v1alpha1.ClusterConfiguration }
<p>
(<em>Appears on:</em>
<a href="#hypershift.openshift.io/v1alpha1.HostedClusterSpec">HostedClusterSpec</a>, 
<a href="#hypershift.openshift.io/v1alpha1.HostedControlPlaneSpec">HostedControlPlaneSpec</a>)
</p>
<p>
<p>ClusterConfiguration specifies configuration for individual OCP components in the
cluster, represented as embedded resources that correspond to the openshift
configuration API.</p>
<p>The API for individual configuration items is at:
<a href="https://docs.openshift.com/container-platform/4.7/rest_api/config_apis/config-apis-index.html">https://docs.openshift.com/container-platform/4.7/rest_api/config_apis/config-apis-index.html</a></p>
</p>
<table>
<thead>
<tr>
<th>Field</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<code>secretRefs</code></br>
<em>
<a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.22/#localobjectreference-v1-core">
[]Kubernetes core/v1.LocalObjectReference
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>SecretRefs holds references to any secrets referenced by configuration
entries. Entries can reference the secrets using local object references.</p>
<p>Deprecated
This field is deprecated and will be removed in a future release</p>
</td>
</tr>
<tr>
<td>
<code>configMapRefs</code></br>
<em>
<a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.22/#localobjectreference-v1-core">
[]Kubernetes core/v1.LocalObjectReference
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>ConfigMapRefs holds references to any configmaps referenced by
configuration entries. Entries can reference the configmaps using local
object references.</p>
<p>Deprecated
This field is deprecated and will be removed in a future release</p>
</td>
</tr>
<tr>
<td>
<code>items</code></br>
<em>
<a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.22/#rawextension-runtime-pkg">
[]k8s.io/apimachinery/pkg/runtime.RawExtension
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>Items embeds the serialized configuration resources.</p>
<p>Deprecated
This field is deprecated and will be removed in a future release</p>
</td>
</tr>
<tr>
<td>
<code>apiServer</code></br>
<em>
<a href="https://docs.openshift.com/container-platform/4.10/rest_api/config_apis/config-apis-index.html">
github.com/openshift/api/config/v1.APIServerSpec
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>APIServer holds configuration (like serving certificates, client CA and CORS domains)
shared by all API servers in the system, among them especially kube-apiserver
and openshift-apiserver.</p>
</td>
</tr>
<tr>
<td>
<code>authentication</code></br>
<em>
<a href="https://docs.openshift.com/container-platform/4.10/rest_api/config_apis/config-apis-index.html">
github.com/openshift/api/config/v1.AuthenticationSpec
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>Authentication specifies cluster-wide settings for authentication (like OAuth and
webhook token authenticators).</p>
</td>
</tr>
<tr>
<td>
<code>featureGate</code></br>
<em>
<a href="https://docs.openshift.com/container-platform/4.10/rest_api/config_apis/config-apis-index.html">
github.com/openshift/api/config/v1.FeatureGateSpec
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>FeatureGate holds cluster-wide information about feature gates.</p>
</td>
</tr>
<tr>
<td>
<code>image</code></br>
<em>
<a href="https://docs.openshift.com/container-platform/4.10/rest_api/config_apis/config-apis-index.html">
github.com/openshift/api/config/v1.ImageSpec
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>Image governs policies related to imagestream imports and runtime configuration
for external registries. It allows cluster admins to configure which registries
OpenShift is allowed to import images from, extra CA trust bundles for external
registries, and policies to block or allow registry hostnames.
When exposing OpenShift&rsquo;s image registry to the public, this also lets cluster
admins specify the external hostname.</p>
</td>
</tr>
<tr>
<td>
<code>ingress</code></br>
<em>
<a href="https://docs.openshift.com/container-platform/4.10/rest_api/config_apis/config-apis-index.html">
github.com/openshift/api/config/v1.IngressSpec
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>Ingress holds cluster-wide information about ingress, including the default ingress domain
used for routes.</p>
</td>
</tr>
<tr>
<td>
<code>network</code></br>
<em>
<a href="https://docs.openshift.com/container-platform/4.10/rest_api/config_apis/config-apis-index.html">
github.com/openshift/api/config/v1.NetworkSpec
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>Network holds cluster-wide information about the network. It is used to configure the desired network configuration, such as: IP address pools for services/pod IPs, network plugin, etc.
Please view network.spec for an explanation on what applies when configuring this resource.
TODO (csrwng): Add validation here to exclude changes that conflict with networking settings in the HostedCluster.Spec.Networking field.</p>
</td>
</tr>
<tr>
<td>
<code>oauth</code></br>
<em>
<a href="https://docs.openshift.com/container-platform/4.10/rest_api/config_apis/config-apis-index.html">
github.com/openshift/api/config/v1.OAuthSpec
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>OAuth holds cluster-wide information about OAuth.
It is used to configure the integrated OAuth server.
This configuration is only honored when the top level Authentication config has type set to IntegratedOAuth.</p>
</td>
</tr>
<tr>
<td>
<code>scheduler</code></br>
<em>
<a href="https://docs.openshift.com/container-platform/4.10/rest_api/config_apis/config-apis-index.html">
github.com/openshift/api/config/v1.SchedulerSpec
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>Scheduler holds cluster-wide config information to run the Kubernetes Scheduler
and influence its placement decisions. The canonical name for this config is <code>cluster</code>.</p>
</td>
</tr>
<tr>
<td>
<code>proxy</code></br>
<em>
<a href="https://docs.openshift.com/container-platform/4.10/rest_api/config_apis/config-apis-index.html">
github.com/openshift/api/config/v1.ProxySpec
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>Proxy holds cluster-wide information on how to configure default proxies for the cluster.</p>
</td>
</tr>
</tbody>
</table>
###ClusterNetworkEntry { #hypershift.openshift.io/v1alpha1.ClusterNetworkEntry }
<p>
(<em>Appears on:</em>
<a href="#hypershift.openshift.io/v1alpha1.ClusterNetworking">ClusterNetworking</a>)
</p>
<p>
<p>ClusterNetworkEntry is a single IP address block for pod IP blocks. IP blocks
are allocated with size 2^HostSubnetLength.</p>
</p>
<table>
<thead>
<tr>
<th>Field</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<code>cidr</code></br>
<em>
<a href="#">
github.com/openshift/hypershift/api/util/ipnet.IPNet
</a>
</em>
</td>
<td>
<p>CIDR is the IP block address pool.</p>
</td>
</tr>
<tr>
<td>
<code>hostPrefix</code></br>
<em>
int32
</em>
</td>
<td>
<em>(Optional)</em>
<p>HostPrefix is the prefix size to allocate to each node from the CIDR.
For example, 24 would allocate 2^8=256 adresses to each node. If this
field is not used by the plugin, it can be left unset.</p>
</td>
</tr>
</tbody>
</table>
###ClusterNetworking { #hypershift.openshift.io/v1alpha1.ClusterNetworking }
<p>
(<em>Appears on:</em>
<a href="#hypershift.openshift.io/v1alpha1.HostedClusterSpec">HostedClusterSpec</a>, 
<a href="#hypershift.openshift.io/v1alpha1.HostedControlPlaneSpec">HostedControlPlaneSpec</a>)
</p>
<p>
<p>ClusterNetworking specifies network configuration for a cluster.</p>
</p>
<table>
<thead>
<tr>
<th>Field</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<code>serviceCIDR</code></br>
<em>
string
</em>
</td>
<td>
<em>(Optional)</em>
<p>Deprecated
This field will be removed in the next API release.
Use ServiceNetwork instead</p>
</td>
</tr>
<tr>
<td>
<code>podCIDR</code></br>
<em>
string
</em>
</td>
<td>
<em>(Optional)</em>
<p>Deprecated
This field will be removed in the next API release.
Use ClusterNetwork instead</p>
</td>
</tr>
<tr>
<td>
<code>machineCIDR</code></br>
<em>
string
</em>
</td>
<td>
<em>(Optional)</em>
<p>Deprecated
This field will be removed in the next API release.
Use MachineNetwork instead</p>
</td>
</tr>
<tr>
<td>
<code>machineNetwork</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.MachineNetworkEntry">
[]MachineNetworkEntry
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>MachineNetwork is the list of IP address pools for machines.
TODO: make this required in the next version of the API</p>
</td>
</tr>
<tr>
<td>
<code>clusterNetwork</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.ClusterNetworkEntry">
[]ClusterNetworkEntry
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>ClusterNetwork is the list of IP address pools for pods.
TODO: make this required in the next version of the API</p>
</td>
</tr>
<tr>
<td>
<code>serviceNetwork</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.ServiceNetworkEntry">
[]ServiceNetworkEntry
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>ServiceNetwork is the list of IP address pools for services.
NOTE: currently only one entry is supported.
TODO: make this required in the next version of the API</p>
</td>
</tr>
<tr>
<td>
<code>networkType</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.NetworkType">
NetworkType
</a>
</em>
</td>
<td>
<p>NetworkType specifies the SDN provider used for cluster networking.</p>
<p>
Value must be one of:
&#34;Calico&#34;, 
&#34;OVNKubernetes&#34;, 
&#34;OpenShiftSDN&#34;, 
&#34;Other&#34;
</p>
</td>
</tr>
<tr>
<td>
<code>apiServer</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.APIServerNetworking">
APIServerNetworking
</a>
</em>
</td>
<td>
<p>APIServer contains advanced network settings for the API server that affect
how the APIServer is exposed inside a cluster node.</p>
</td>
</tr>
</tbody>
</table>
###ClusterVersionStatus { #hypershift.openshift.io/v1alpha1.ClusterVersionStatus }
<p>
(<em>Appears on:</em>
<a href="#hypershift.openshift.io/v1alpha1.HostedClusterStatus">HostedClusterStatus</a>)
</p>
<p>
<p>ClusterVersionStatus reports the status of the cluster versioning,
including any upgrades that are in progress. The current field will
be set to whichever version the cluster is reconciling to, and the
conditions array will report whether the update succeeded, is in
progress, or is failing.</p>
</p>
<table>
<thead>
<tr>
<th>Field</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<code>desired</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.Release">
Release
</a>
</em>
</td>
<td>
<p>desired is the version that the cluster is reconciling towards.
If the cluster is not yet fully initialized desired will be set
with the information available, which may be an image or a tag.</p>
</td>
</tr>
<tr>
<td>
<code>history</code></br>
<em>
<a href="https://docs.openshift.com/container-platform/4.10/rest_api/config_apis/config-apis-index.html">
[]github.com/openshift/api/config/v1.UpdateHistory
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>history contains a list of the most recent versions applied to the cluster.
This value may be empty during cluster startup, and then will be updated
when a new update is being applied. The newest update is first in the
list and it is ordered by recency. Updates in the history have state
Completed if the rollout completed - if an update was failing or halfway
applied the state will be Partial. Only a limited amount of update history
is preserved.</p>
</td>
</tr>
<tr>
<td>
<code>observedGeneration</code></br>
<em>
int64
</em>
</td>
<td>
<p>observedGeneration reports which version of the spec is being synced.
If this value is not equal to metadata.generation, then the desired
and conditions fields may represent a previous version.</p>
</td>
</tr>
</tbody>
</table>
###ConditionType { #hypershift.openshift.io/v1alpha1.ConditionType }
<p>
</p>
<table>
<thead>
<tr>
<th>Value</th>
<th>Description</th>
</tr>
</thead>
<tbody><tr><td><p>&#34;EndpointAvailable&#34;</p></td>
<td><p>AWSEndpointServiceAvailable indicates whether the AWS Endpoint has been
created in the guest VPC</p>
</td>
</tr><tr><td><p>&#34;EndpointServiceAvailable&#34;</p></td>
<td><p>AWSEndpointServiceAvailable indicates whether the AWS Endpoint Service
has been created for the specified NLB in the management VPC</p>
</td>
</tr><tr><td><p>&#34;CVOScaledDown&#34;</p></td>
<td></td>
</tr><tr><td><p>&#34;CloudResourcesDestroyed&#34;</p></td>
<td></td>
</tr><tr><td><p>&#34;ClusterVersionFailing&#34;</p></td>
<td></td>
</tr><tr><td><p>&#34;ClusterVersionSucceeding&#34;</p></td>
<td><p>ClusterVersionSucceeding indicates the current status of the desired release
version of the HostedCluster as indicated by the Failing condition in the
underlying cluster&rsquo;s ClusterVersion.</p>
</td>
</tr><tr><td><p>&#34;ClusterVersionUpgradeable&#34;</p></td>
<td><p>ClusterVersionUpgradeable indicates the Upgradeable condition in the
underlying cluster&rsquo;s ClusterVersion.</p>
</td>
</tr><tr><td><p>&#34;EtcdAvailable&#34;</p></td>
<td></td>
</tr><tr><td><p>&#34;EtcdSnapshotRestored&#34;</p></td>
<td></td>
</tr><tr><td><p>&#34;Available&#34;</p></td>
<td><p>HostedClusterAvailable indicates whether the HostedCluster has a healthy
control plane.</p>
</td>
</tr><tr><td><p>&#34;Degraded&#34;</p></td>
<td><p>HostedClusterDegraded indicates whether the HostedCluster is encountering
an error that may require user intervention to resolve.</p>
</td>
</tr><tr><td><p>&#34;Progressing&#34;</p></td>
<td><p>HostedClusterProgressing indicates whether the HostedCluster is attempting
an initial deployment or upgrade.</p>
</td>
</tr><tr><td><p>&#34;Available&#34;</p></td>
<td></td>
</tr><tr><td><p>&#34;Degraded&#34;</p></td>
<td></td>
</tr><tr><td><p>&#34;IgnitionEndpointAvailable&#34;</p></td>
<td><p>IgnitionEndpointAvailable indicates whether the ignition server for the
HostedCluster is available to handle ignition requests.</p>
</td>
</tr><tr><td><p>&#34;InfrastructureReady&#34;</p></td>
<td></td>
</tr><tr><td><p>&#34;KubeAPIServerAvailable&#34;</p></td>
<td></td>
</tr><tr><td><p>&#34;PlatformCredentialsFound&#34;</p></td>
<td><p>PlatformCredentialsFound indicates that credentials required for the
desired platform are valid.</p>
</td>
</tr><tr><td><p>&#34;ReconciliationActive&#34;</p></td>
<td><p>ReconciliationActive indicates if reconciliation of the hostedcluster is
active or paused.</p>
</td>
</tr><tr><td><p>&#34;ReconciliationSucceeded&#34;</p></td>
<td><p>ReconciliationSucceeded indicates if the hostedcluster reconciliation
succeeded.</p>
</td>
</tr><tr><td><p>&#34;SupportedHostedCluster&#34;</p></td>
<td><p>SupportedHostedCluster indicates whether a HostedCluster is supported by
the current configuration of the hypershift-operator.
e.g. If HostedCluster requests endpointAcess Private but the hypershift-operator
is running on a management cluster outside AWS or is not configured with AWS
credentials, the HostedCluster is not supported.</p>
</td>
</tr><tr><td><p>&#34;UnmanagedEtcdAvailable&#34;</p></td>
<td><p>UnmanagedEtcdAvailable indicates whether a user-managed etcd cluster is
healthy.</p>
</td>
</tr><tr><td><p>&#34;ValidConfiguration&#34;</p></td>
<td><p>ValidHostedClusterConfiguration indicates (if status is true) that the
ClusterConfiguration specified for the HostedCluster is valid.</p>
</td>
</tr><tr><td><p>&#34;ValidHostedControlPlaneConfiguration&#34;</p></td>
<td></td>
</tr><tr><td><p>&#34;ValidOIDCConfiguration&#34;</p></td>
<td><p>ValidOIDCConfiguration indicates if an AWS cluster&rsquo;s OIDC condition is
detected as invalid.</p>
</td>
</tr><tr><td><p>&#34;ValidReleaseImage&#34;</p></td>
<td><p>ValidReleaseImage indicates if the release image set in the spec is valid
for the HostedCluster. For example, this can be set false if the
HostedCluster itself attempts an unsupported version before 4.9 or an
unsupported upgrade e.g y-stream upgrade before 4.11.</p>
</td>
</tr></tbody>
</table>
###DNSSpec { #hypershift.openshift.io/v1alpha1.DNSSpec }
<p>
(<em>Appears on:</em>
<a href="#hypershift.openshift.io/v1alpha1.HostedClusterSpec">HostedClusterSpec</a>, 
<a href="#hypershift.openshift.io/v1alpha1.HostedControlPlaneSpec">HostedControlPlaneSpec</a>)
</p>
<p>
<p>DNSSpec specifies the DNS configuration in the cluster.</p>
</p>
<table>
<thead>
<tr>
<th>Field</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<code>baseDomain</code></br>
<em>
string
</em>
</td>
<td>
<p>BaseDomain is the base domain of the cluster.</p>
</td>
</tr>
<tr>
<td>
<code>publicZoneID</code></br>
<em>
string
</em>
</td>
<td>
<em>(Optional)</em>
<p>PublicZoneID is the Hosted Zone ID where all the DNS records that are
publicly accessible to the internet exist.</p>
</td>
</tr>
<tr>
<td>
<code>privateZoneID</code></br>
<em>
string
</em>
</td>
<td>
<em>(Optional)</em>
<p>PrivateZoneID is the Hosted Zone ID where all the DNS records that are only
available internally to the cluster exist.</p>
</td>
</tr>
</tbody>
</table>
###EtcdManagementType { #hypershift.openshift.io/v1alpha1.EtcdManagementType }
<p>
(<em>Appears on:</em>
<a href="#hypershift.openshift.io/v1alpha1.EtcdSpec">EtcdSpec</a>)
</p>
<p>
<p>EtcdManagementType is a enum specifying the strategy for managing the cluster&rsquo;s etcd instance</p>
</p>
<table>
<thead>
<tr>
<th>Value</th>
<th>Description</th>
</tr>
</thead>
<tbody><tr><td><p>&#34;Managed&#34;</p></td>
<td><p>Managed means HyperShift should provision and operator the etcd cluster
automatically.</p>
</td>
</tr><tr><td><p>&#34;Unmanaged&#34;</p></td>
<td><p>Unmanaged means HyperShift will not provision or manage the etcd cluster,
and the user is responsible for doing so.</p>
</td>
</tr></tbody>
</table>
###EtcdSpec { #hypershift.openshift.io/v1alpha1.EtcdSpec }
<p>
(<em>Appears on:</em>
<a href="#hypershift.openshift.io/v1alpha1.HostedClusterSpec">HostedClusterSpec</a>, 
<a href="#hypershift.openshift.io/v1alpha1.HostedControlPlaneSpec">HostedControlPlaneSpec</a>)
</p>
<p>
<p>EtcdSpec specifies configuration for a control plane etcd cluster.</p>
</p>
<table>
<thead>
<tr>
<th>Field</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<code>managementType</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.EtcdManagementType">
EtcdManagementType
</a>
</em>
</td>
<td>
<p>ManagementType defines how the etcd cluster is managed.</p>
<p>
Value must be one of:
&#34;Managed&#34;, 
&#34;Unmanaged&#34;
</p>
</td>
</tr>
<tr>
<td>
<code>managed</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.ManagedEtcdSpec">
ManagedEtcdSpec
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>Managed specifies the behavior of an etcd cluster managed by HyperShift.</p>
</td>
</tr>
<tr>
<td>
<code>unmanaged</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.UnmanagedEtcdSpec">
UnmanagedEtcdSpec
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>Unmanaged specifies configuration which enables the control plane to
integrate with an eternally managed etcd cluster.</p>
</td>
</tr>
</tbody>
</table>
###EtcdTLSConfig { #hypershift.openshift.io/v1alpha1.EtcdTLSConfig }
<p>
(<em>Appears on:</em>
<a href="#hypershift.openshift.io/v1alpha1.UnmanagedEtcdSpec">UnmanagedEtcdSpec</a>)
</p>
<p>
<p>EtcdTLSConfig specifies TLS configuration for HTTPS etcd client endpoints.</p>
</p>
<table>
<thead>
<tr>
<th>Field</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<code>clientSecret</code></br>
<em>
<a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.22/#localobjectreference-v1-core">
Kubernetes core/v1.LocalObjectReference
</a>
</em>
</td>
<td>
<p>ClientSecret refers to a secret for client mTLS authentication with the etcd cluster. It
may have the following key/value pairs:</p>
<pre><code>etcd-client-ca.crt: Certificate Authority value
etcd-client.crt: Client certificate value
etcd-client.key: Client certificate key value
</code></pre>
</td>
</tr>
</tbody>
</table>
###Filter { #hypershift.openshift.io/v1alpha1.Filter }
<p>
(<em>Appears on:</em>
<a href="#hypershift.openshift.io/v1alpha1.AWSResourceReference">AWSResourceReference</a>)
</p>
<p>
<p>Filter is a filter used to identify an AWS resource</p>
</p>
<table>
<thead>
<tr>
<th>Field</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<code>name</code></br>
<em>
string
</em>
</td>
<td>
<p>Name of the filter. Filter names are case-sensitive.</p>
</td>
</tr>
<tr>
<td>
<code>values</code></br>
<em>
[]string
</em>
</td>
<td>
<p>Values includes one or more filter values. Filter values are case-sensitive.</p>
</td>
</tr>
</tbody>
</table>
###HostedClusterSpec { #hypershift.openshift.io/v1alpha1.HostedClusterSpec }
<p>
(<em>Appears on:</em>
<a href="#hypershift.openshift.io/v1alpha1.HostedCluster">HostedCluster</a>)
</p>
<p>
<p>HostedClusterSpec is the desired behavior of a HostedCluster.</p>
</p>
<table>
<thead>
<tr>
<th>Field</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<code>release</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.Release">
Release
</a>
</em>
</td>
<td>
<p>Release specifies the desired OCP release payload for the hosted cluster.</p>
<p>Updating this field will trigger a rollout of the control plane. The
behavior of the rollout will be driven by the ControllerAvailabilityPolicy
and InfrastructureAvailabilityPolicy.</p>
</td>
</tr>
<tr>
<td>
<code>clusterID</code></br>
<em>
string
</em>
</td>
<td>
<em>(Optional)</em>
<p>ClusterID uniquely identifies this cluster. This is expected to be
an RFC4122 UUID value (xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx in
hexadecimal values).
As with a Kubernetes metadata.uid, this ID uniquely identifies this
cluster in space and time.
This value identifies the cluster in metrics pushed to telemetry and
metrics produced by the control plane operators. If a value is not
specified, an ID is generated. After initial creation, the value is
immutable.</p>
</td>
</tr>
<tr>
<td>
<code>infraID</code></br>
<em>
string
</em>
</td>
<td>
<em>(Optional)</em>
<p>InfraID is a globally unique identifier for the cluster. This identifier
will be used to associate various cloud resources with the HostedCluster
and its associated NodePools.</p>
</td>
</tr>
<tr>
<td>
<code>platform</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.PlatformSpec">
PlatformSpec
</a>
</em>
</td>
<td>
<p>Platform specifies the underlying infrastructure provider for the cluster
and is used to configure platform specific behavior.</p>
</td>
</tr>
<tr>
<td>
<code>controllerAvailabilityPolicy</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.AvailabilityPolicy">
AvailabilityPolicy
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>ControllerAvailabilityPolicy specifies the availability policy applied to
critical control plane components. The default value is SingleReplica.</p>
<p>
Value must be one of:
&#34;HighlyAvailable&#34;, 
&#34;SingleReplica&#34;
</p>
</td>
</tr>
<tr>
<td>
<code>infrastructureAvailabilityPolicy</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.AvailabilityPolicy">
AvailabilityPolicy
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>InfrastructureAvailabilityPolicy specifies the availability policy applied
to infrastructure services which run on cluster nodes. The default value is
SingleReplica.</p>
<p>
Value must be one of:
&#34;HighlyAvailable&#34;, 
&#34;SingleReplica&#34;
</p>
</td>
</tr>
<tr>
<td>
<code>dns</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.DNSSpec">
DNSSpec
</a>
</em>
</td>
<td>
<p>DNS specifies DNS configuration for the cluster.</p>
</td>
</tr>
<tr>
<td>
<code>networking</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.ClusterNetworking">
ClusterNetworking
</a>
</em>
</td>
<td>
<p>Networking specifies network configuration for the cluster.</p>
</td>
</tr>
<tr>
<td>
<code>autoscaling</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.ClusterAutoscaling">
ClusterAutoscaling
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>Autoscaling specifies auto-scaling behavior that applies to all NodePools
associated with the control plane.</p>
</td>
</tr>
<tr>
<td>
<code>etcd</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.EtcdSpec">
EtcdSpec
</a>
</em>
</td>
<td>
<p>Etcd specifies configuration for the control plane etcd cluster. The
default ManagementType is Managed. Once set, the ManagementType cannot be
changed.</p>
</td>
</tr>
<tr>
<td>
<code>services</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.ServicePublishingStrategyMapping">
[]ServicePublishingStrategyMapping
</a>
</em>
</td>
<td>
<p>Services specifies how individual control plane services are published from
the hosting cluster of the control plane.</p>
<p>If a given service is not present in this list, it will be exposed publicly
by default.</p>
</td>
</tr>
<tr>
<td>
<code>pullSecret</code></br>
<em>
<a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.22/#localobjectreference-v1-core">
Kubernetes core/v1.LocalObjectReference
</a>
</em>
</td>
<td>
<p>PullSecret references a pull secret to be injected into the container
runtime of all cluster nodes. The secret must have a key named
&ldquo;.dockerconfigjson&rdquo; whose value is the pull secret JSON.</p>
</td>
</tr>
<tr>
<td>
<code>sshKey</code></br>
<em>
<a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.22/#localobjectreference-v1-core">
Kubernetes core/v1.LocalObjectReference
</a>
</em>
</td>
<td>
<p>SSHKey references an SSH key to be injected into all cluster node sshd
servers. The secret must have a single key &ldquo;id_rsa.pub&rdquo; whose value is the
public part of an SSH key.</p>
</td>
</tr>
<tr>
<td>
<code>issuerURL</code></br>
<em>
string
</em>
</td>
<td>
<em>(Optional)</em>
<p>IssuerURL is an OIDC issuer URL which is used as the issuer in all
ServiceAccount tokens generated by the control plane API server. The
default value is kubernetes.default.svc, which only works for in-cluster
validation.</p>
</td>
</tr>
<tr>
<td>
<code>serviceAccountSigningKey</code></br>
<em>
<a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.22/#localobjectreference-v1-core">
Kubernetes core/v1.LocalObjectReference
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>ServiceAccountSigningKey is a reference to a secret containing the private key
used by the service account token issuer. The secret is expected to contain
a single key named &ldquo;key&rdquo;. If not specified, a service account signing key will
be generated automatically for the cluster. When specifying a service account
signing key, a IssuerURL must also be specified.</p>
</td>
</tr>
<tr>
<td>
<code>configuration</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.ClusterConfiguration">
ClusterConfiguration
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>Configuration specifies configuration for individual OCP components in the
cluster, represented as embedded resources that correspond to the openshift
configuration API.</p>
</td>
</tr>
<tr>
<td>
<code>auditWebhook</code></br>
<em>
<a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.22/#localobjectreference-v1-core">
Kubernetes core/v1.LocalObjectReference
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>AuditWebhook contains metadata for configuring an audit webhook endpoint
for a cluster to process cluster audit events. It references a secret that
contains the webhook information for the audit webhook endpoint. It is a
secret because if the endpoint has mTLS the kubeconfig will contain client
keys. The kubeconfig needs to be stored in the secret with a secret key
name that corresponds to the constant AuditWebhookKubeconfigKey.</p>
<p>This field is currently only supported on the IBMCloud platform.</p>
</td>
</tr>
<tr>
<td>
<code>imageContentSources</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.ImageContentSource">
[]ImageContentSource
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>ImageContentSources specifies image mirrors that can be used by cluster
nodes to pull content.</p>
</td>
</tr>
<tr>
<td>
<code>additionalTrustBundle</code></br>
<em>
<a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.22/#localobjectreference-v1-core">
Kubernetes core/v1.LocalObjectReference
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>AdditionalTrustBundle is a reference to a ConfigMap containing a
PEM-encoded X.509 certificate bundle that will be added to the hosted controlplane and nodes</p>
</td>
</tr>
<tr>
<td>
<code>secretEncryption</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.SecretEncryptionSpec">
SecretEncryptionSpec
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>SecretEncryption specifies a Kubernetes secret encryption strategy for the
control plane.</p>
</td>
</tr>
<tr>
<td>
<code>fips</code></br>
<em>
bool
</em>
</td>
<td>
<em>(Optional)</em>
<p>FIPS indicates whether this cluster&rsquo;s nodes will be running in FIPS mode.
If set to true, the control plane&rsquo;s ignition server will be configured to
expect that nodes joining the cluster will be FIPS-enabled.</p>
</td>
</tr>
<tr>
<td>
<code>pausedUntil</code></br>
<em>
string
</em>
</td>
<td>
<em>(Optional)</em>
<p>PausedUntil is a field that can be used to pause reconciliation on a resource.
Either a date can be provided in RFC3339 format or a boolean. If a date is
provided: reconciliation is paused on the resource until that date. If the boolean true is
provided: reconciliation is paused on the resource until the field is removed.</p>
</td>
</tr>
<tr>
<td>
<code>olmCatalogPlacement</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.OLMCatalogPlacement">
OLMCatalogPlacement
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>OLMCatalogPlacement specifies the placement of OLM catalog components. By default,
this is set to management and OLM catalog components are deployed onto the management
cluster. If set to guest, the OLM catalog components will be deployed onto the guest
cluster.</p>
<p>
Value must be one of:
&#34;guest&#34;, 
&#34;management&#34;
</p>
</td>
</tr>
<tr>
<td>
<code>nodeSelector</code></br>
<em>
map[string]string
</em>
</td>
<td>
<em>(Optional)</em>
<p>NodeSelector when specified, must be true for the pods managed by the HostedCluster to be scheduled.</p>
</td>
</tr>
</tbody>
</table>
###HostedClusterStatus { #hypershift.openshift.io/v1alpha1.HostedClusterStatus }
<p>
(<em>Appears on:</em>
<a href="#hypershift.openshift.io/v1alpha1.HostedCluster">HostedCluster</a>)
</p>
<p>
<p>HostedClusterStatus is the latest observed status of a HostedCluster.</p>
</p>
<table>
<thead>
<tr>
<th>Field</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<code>version</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.ClusterVersionStatus">
ClusterVersionStatus
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>Version is the status of the release version applied to the
HostedCluster.</p>
</td>
</tr>
<tr>
<td>
<code>kubeconfig</code></br>
<em>
<a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.22/#localobjectreference-v1-core">
Kubernetes core/v1.LocalObjectReference
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>KubeConfig is a reference to the secret containing the default kubeconfig
for the cluster.</p>
</td>
</tr>
<tr>
<td>
<code>kubeadminPassword</code></br>
<em>
<a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.22/#localobjectreference-v1-core">
Kubernetes core/v1.LocalObjectReference
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>KubeadminPassword is a reference to the secret that contains the initial
kubeadmin user password for the guest cluster.</p>
</td>
</tr>
<tr>
<td>
<code>ignitionEndpoint</code></br>
<em>
string
</em>
</td>
<td>
<em>(Optional)</em>
<p>IgnitionEndpoint is the endpoint injected in the ign config userdata.
It exposes the config for instances to become kubernetes nodes.</p>
</td>
</tr>
<tr>
<td>
<code>oauthCallbackURLTemplate</code></br>
<em>
string
</em>
</td>
<td>
<p>OAuthCallbackURLTemplate contains a template for the URL to use as a callback
for identity providers. The [identity-provider-name] placeholder must be replaced
with the name of an identity provider defined on the HostedCluster.
This is populated after the infrastructure is ready.</p>
</td>
</tr>
<tr>
<td>
<code>conditions</code></br>
<em>
<a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.22/#condition-v1-meta">
[]Kubernetes meta/v1.Condition
</a>
</em>
</td>
<td>
<p>Conditions represents the latest available observations of a control
plane&rsquo;s current state.</p>
</td>
</tr>
</tbody>
</table>
###HostedControlPlaneSpec { #hypershift.openshift.io/v1alpha1.HostedControlPlaneSpec }
<p>
<p>HostedControlPlaneSpec defines the desired state of HostedControlPlane</p>
</p>
<table>
<thead>
<tr>
<th>Field</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<code>releaseImage</code></br>
<em>
string
</em>
</td>
<td>
</td>
</tr>
<tr>
<td>
<code>pullSecret</code></br>
<em>
<a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.22/#localobjectreference-v1-core">
Kubernetes core/v1.LocalObjectReference
</a>
</em>
</td>
<td>
</td>
</tr>
<tr>
<td>
<code>issuerURL</code></br>
<em>
string
</em>
</td>
<td>
</td>
</tr>
<tr>
<td>
<code>networking</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.ClusterNetworking">
ClusterNetworking
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>Networking specifies network configuration for the cluster.
Temporarily optional for backward compatibility, required in future releases.</p>
</td>
</tr>
<tr>
<td>
<code>serviceCIDR</code></br>
<em>
string
</em>
</td>
<td>
<em>(Optional)</em>
<p>deprecated
use networking.ServiceNetwork</p>
</td>
</tr>
<tr>
<td>
<code>podCIDR</code></br>
<em>
string
</em>
</td>
<td>
<em>(Optional)</em>
<p>deprecated
use networking.ClusterNetwork</p>
</td>
</tr>
<tr>
<td>
<code>machineCIDR</code></br>
<em>
string
</em>
</td>
<td>
<em>(Optional)</em>
<p>deprecated
use networking.MachineNetwork</p>
</td>
</tr>
<tr>
<td>
<code>networkType</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.NetworkType">
NetworkType
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>deprecated
use networking.NetworkType
NetworkType specifies the SDN provider used for cluster networking.</p>
<p>
Value must be one of:
&#34;Calico&#34;, 
&#34;OVNKubernetes&#34;, 
&#34;OpenShiftSDN&#34;, 
&#34;Other&#34;
</p>
</td>
</tr>
<tr>
<td>
<code>sshKey</code></br>
<em>
<a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.22/#localobjectreference-v1-core">
Kubernetes core/v1.LocalObjectReference
</a>
</em>
</td>
<td>
</td>
</tr>
<tr>
<td>
<code>clusterID</code></br>
<em>
string
</em>
</td>
<td>
<em>(Optional)</em>
<p>ClusterID is the unique id that identifies the cluster externally.
Making it optional here allows us to keep compatibility with previous
versions of the control-plane-operator that have no knowledge of this
field.</p>
</td>
</tr>
<tr>
<td>
<code>infraID</code></br>
<em>
string
</em>
</td>
<td>
</td>
</tr>
<tr>
<td>
<code>platform</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.PlatformSpec">
PlatformSpec
</a>
</em>
</td>
<td>
</td>
</tr>
<tr>
<td>
<code>dns</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.DNSSpec">
DNSSpec
</a>
</em>
</td>
<td>
</td>
</tr>
<tr>
<td>
<code>serviceAccountSigningKey</code></br>
<em>
<a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.22/#localobjectreference-v1-core">
Kubernetes core/v1.LocalObjectReference
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>ServiceAccountSigningKey is a reference to a secret containing the private key
used by the service account token issuer. The secret is expected to contain
a single key named &ldquo;key&rdquo;. If not specified, a service account signing key will
be generated automatically for the cluster.</p>
</td>
</tr>
<tr>
<td>
<code>apiPort</code></br>
<em>
int32
</em>
</td>
<td>
<em>(Optional)</em>
<p>deprecated
use networking.apiServer.APIPort
APIPort is the port at which the APIServer listens inside a worker</p>
</td>
</tr>
<tr>
<td>
<code>apiAdvertiseAddress</code></br>
<em>
string
</em>
</td>
<td>
<em>(Optional)</em>
<p>deprecated
use networking.apiServer.AdvertiseAddress
APIAdvertiseAddress is the address at which the APIServer listens
inside a worker.</p>
</td>
</tr>
<tr>
<td>
<code>apiAllowedCIDRBlocks</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.CIDRBlock">
[]CIDRBlock
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>deprecated
use networking.apiServer.APIAllowedCIDRBlocks
APIAllowedCIDRBlocks is an allow list of CIDR blocks that can access the APIServer
If not specified, traffic is allowed from all addresses.
This depends on underlying support by the cloud provider for Service LoadBalancerSourceRanges</p>
</td>
</tr>
<tr>
<td>
<code>controllerAvailabilityPolicy</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.AvailabilityPolicy">
AvailabilityPolicy
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>ControllerAvailabilityPolicy specifies the availability policy applied to
critical control plane components. The default value is SingleReplica.</p>
<p>
Value must be one of:
&#34;HighlyAvailable&#34;, 
&#34;SingleReplica&#34;
</p>
</td>
</tr>
<tr>
<td>
<code>infrastructureAvailabilityPolicy</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.AvailabilityPolicy">
AvailabilityPolicy
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>InfrastructureAvailabilityPolicy specifies the availability policy applied
to infrastructure services which run on cluster nodes. The default value is
SingleReplica.</p>
<p>
Value must be one of:
&#34;HighlyAvailable&#34;, 
&#34;SingleReplica&#34;
</p>
</td>
</tr>
<tr>
<td>
<code>fips</code></br>
<em>
bool
</em>
</td>
<td>
<em>(Optional)</em>
<p>FIPS specifies if the nodes for the cluster will be running in FIPS mode</p>
</td>
</tr>
<tr>
<td>
<code>kubeconfig</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.KubeconfigSecretRef">
KubeconfigSecretRef
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>KubeConfig specifies the name and key for the kubeconfig secret</p>
</td>
</tr>
<tr>
<td>
<code>services</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.ServicePublishingStrategyMapping">
[]ServicePublishingStrategyMapping
</a>
</em>
</td>
<td>
<p>Services defines metadata about how control plane services are published
in the management cluster.</p>
</td>
</tr>
<tr>
<td>
<code>auditWebhook</code></br>
<em>
<a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.22/#localobjectreference-v1-core">
Kubernetes core/v1.LocalObjectReference
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>AuditWebhook contains metadata for configuring an audit webhook
endpoint for a cluster to process cluster audit events. It references
a secret that contains the webhook information for the audit webhook endpoint.
It is a secret because if the endpoint has MTLS the kubeconfig will contain client
keys. This is currently only supported in IBM Cloud. The kubeconfig needs to be stored
in the secret with a secret key name that corresponds to the constant AuditWebhookKubeconfigKey.</p>
</td>
</tr>
<tr>
<td>
<code>etcd</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.EtcdSpec">
EtcdSpec
</a>
</em>
</td>
<td>
<p>Etcd contains metadata about the etcd cluster the hypershift managed Openshift control plane components
use to store data.</p>
</td>
</tr>
<tr>
<td>
<code>configuration</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.ClusterConfiguration">
ClusterConfiguration
</a>
</em>
</td>
<td>
<p>Configuration embeds resources that correspond to the openshift configuration API:
<a href="https://docs.openshift.com/container-platform/4.7/rest_api/config_apis/config-apis-index.html">https://docs.openshift.com/container-platform/4.7/rest_api/config_apis/config-apis-index.html</a></p>
</td>
</tr>
<tr>
<td>
<code>imageContentSources</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.ImageContentSource">
[]ImageContentSource
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>ImageContentSources lists sources/repositories for the release-image content.</p>
</td>
</tr>
<tr>
<td>
<code>additionalTrustBundle</code></br>
<em>
<a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.22/#localobjectreference-v1-core">
Kubernetes core/v1.LocalObjectReference
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>AdditionalTrustBundle references a ConfigMap containing a PEM-encoded X.509 certificate bundle</p>
</td>
</tr>
<tr>
<td>
<code>secretEncryption</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.SecretEncryptionSpec">
SecretEncryptionSpec
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>SecretEncryption contains metadata about the kubernetes secret encryption strategy being used for the
cluster when applicable.</p>
</td>
</tr>
<tr>
<td>
<code>pausedUntil</code></br>
<em>
string
</em>
</td>
<td>
<em>(Optional)</em>
<p>PausedUntil is a field that can be used to pause reconciliation on a resource.
Either a date can be provided in RFC3339 format or a boolean. If a date is
provided: reconciliation is paused on the resource until that date. If the boolean true is
provided: reconciliation is paused on the resource until the field is removed.</p>
</td>
</tr>
<tr>
<td>
<code>olmCatalogPlacement</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.OLMCatalogPlacement">
OLMCatalogPlacement
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>OLMCatalogPlacement specifies the placement of OLM catalog components. By default,
this is set to management and OLM catalog components are deployed onto the management
cluster. If set to guest, the OLM catalog components will be deployed onto the guest
cluster.</p>
<p>
Value must be one of:
&#34;guest&#34;, 
&#34;management&#34;
</p>
</td>
</tr>
<tr>
<td>
<code>autoscaling</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.ClusterAutoscaling">
ClusterAutoscaling
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>Autoscaling specifies auto-scaling behavior that applies to all NodePools
associated with the control plane.</p>
</td>
</tr>
<tr>
<td>
<code>nodeSelector</code></br>
<em>
map[string]string
</em>
</td>
<td>
<em>(Optional)</em>
<p>NodeSelector when specified, must be true for the pods managed by the HostedCluster to be scheduled.</p>
</td>
</tr>
</tbody>
</table>
###HostedControlPlaneStatus { #hypershift.openshift.io/v1alpha1.HostedControlPlaneStatus }
<p>
<p>HostedControlPlaneStatus defines the observed state of HostedControlPlane</p>
</p>
<table>
<thead>
<tr>
<th>Field</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<code>ready</code></br>
<em>
bool
</em>
</td>
<td>
<p>Ready denotes that the HostedControlPlane API Server is ready to
receive requests
This satisfies CAPI contract <a href="https://github.com/kubernetes-sigs/cluster-api/blob/cd3a694deac89d5ebeb888307deaa61487207aa0/controllers/cluster_controller_phases.go#L226-L230">https://github.com/kubernetes-sigs/cluster-api/blob/cd3a694deac89d5ebeb888307deaa61487207aa0/controllers/cluster_controller_phases.go#L226-L230</a></p>
</td>
</tr>
<tr>
<td>
<code>initialized</code></br>
<em>
bool
</em>
</td>
<td>
<p>Initialized denotes whether or not the control plane has
provided a kubeadm-config.
Once this condition is marked true, its value is never changed. See the Ready condition for an indication of
the current readiness of the cluster&rsquo;s control plane.
This satisfies CAPI contract <a href="https://github.com/kubernetes-sigs/cluster-api/blob/cd3a694deac89d5ebeb888307deaa61487207aa0/controllers/cluster_controller_phases.go#L238-L252">https://github.com/kubernetes-sigs/cluster-api/blob/cd3a694deac89d5ebeb888307deaa61487207aa0/controllers/cluster_controller_phases.go#L238-L252</a></p>
</td>
</tr>
<tr>
<td>
<code>externalManagedControlPlane</code></br>
<em>
bool
</em>
</td>
<td>
<p>ExternalManagedControlPlane indicates to cluster-api that the control plane
is managed by an external service.
<a href="https://github.com/kubernetes-sigs/cluster-api/blob/65e5385bffd71bf4aad3cf34a537f11b217c7fab/controllers/machine_controller.go#L468">https://github.com/kubernetes-sigs/cluster-api/blob/65e5385bffd71bf4aad3cf34a537f11b217c7fab/controllers/machine_controller.go#L468</a></p>
</td>
</tr>
<tr>
<td>
<code>controlPlaneEndpoint</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.APIEndpoint">
APIEndpoint
</a>
</em>
</td>
<td>
<p>ControlPlaneEndpoint contains the endpoint information by which
external clients can access the control plane.  This is populated
after the infrastructure is ready.</p>
</td>
</tr>
<tr>
<td>
<code>oauthCallbackURLTemplate</code></br>
<em>
string
</em>
</td>
<td>
<p>OAuthCallbackURLTemplate contains a template for the URL to use as a callback
for identity providers. The [identity-provider-name] placeholder must be replaced
with the name of an identity provider defined on the HostedCluster.
This is populated after the infrastructure is ready.</p>
</td>
</tr>
<tr>
<td>
<code>version</code></br>
<em>
string
</em>
</td>
<td>
<p>Version is the semantic version of the release applied by
the hosted control plane operator</p>
</td>
</tr>
<tr>
<td>
<code>releaseImage</code></br>
<em>
string
</em>
</td>
<td>
<p>ReleaseImage is the release image applied to the hosted control plane.</p>
</td>
</tr>
<tr>
<td>
<code>lastReleaseImageTransitionTime</code></br>
<em>
<a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.22/#time-v1-meta">
Kubernetes meta/v1.Time
</a>
</em>
</td>
<td>
<p>lastReleaseImageTransitionTime is the time of the last update to the current
releaseImage property.</p>
</td>
</tr>
<tr>
<td>
<code>kubeConfig</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.KubeconfigSecretRef">
KubeconfigSecretRef
</a>
</em>
</td>
<td>
<p>KubeConfig is a reference to the secret containing the default kubeconfig
for this control plane.</p>
</td>
</tr>
<tr>
<td>
<code>kubeadminPassword</code></br>
<em>
<a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.22/#localobjectreference-v1-core">
Kubernetes core/v1.LocalObjectReference
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>KubeadminPassword is a reference to the secret containing the initial kubeadmin password
for the guest cluster.</p>
</td>
</tr>
<tr>
<td>
<code>conditions</code></br>
<em>
<a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.22/#condition-v1-meta">
[]Kubernetes meta/v1.Condition
</a>
</em>
</td>
<td>
<p>Condition contains details for one aspect of the current state of the HostedControlPlane.
Current condition types are: &ldquo;Available&rdquo;</p>
</td>
</tr>
</tbody>
</table>
###IBMCloudKMSAuthSpec { #hypershift.openshift.io/v1alpha1.IBMCloudKMSAuthSpec }
<p>
(<em>Appears on:</em>
<a href="#hypershift.openshift.io/v1alpha1.IBMCloudKMSSpec">IBMCloudKMSSpec</a>)
</p>
<p>
<p>IBMCloudKMSAuthSpec defines metadata for how authentication is done with IBM Cloud KMS</p>
</p>
<table>
<thead>
<tr>
<th>Field</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<code>type</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.IBMCloudKMSAuthType">
IBMCloudKMSAuthType
</a>
</em>
</td>
<td>
<p>Type defines the IBM Cloud KMS authentication strategy</p>
<p>
Value must be one of:
&#34;Managed&#34;, 
&#34;Unmanaged&#34;
</p>
</td>
</tr>
<tr>
<td>
<code>unmanaged</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.IBMCloudKMSUnmanagedAuthSpec">
IBMCloudKMSUnmanagedAuthSpec
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>Unmanaged defines the auth metadata the customer provides to interact with IBM Cloud KMS</p>
</td>
</tr>
<tr>
<td>
<code>managed</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.IBMCloudKMSManagedAuthSpec">
IBMCloudKMSManagedAuthSpec
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>Managed defines metadata around the service to service authentication strategy for the IBM Cloud
KMS system (all provider managed).</p>
</td>
</tr>
</tbody>
</table>
###IBMCloudKMSAuthType { #hypershift.openshift.io/v1alpha1.IBMCloudKMSAuthType }
<p>
(<em>Appears on:</em>
<a href="#hypershift.openshift.io/v1alpha1.IBMCloudKMSAuthSpec">IBMCloudKMSAuthSpec</a>)
</p>
<p>
<p>IBMCloudKMSAuthType defines the IBM Cloud KMS authentication strategy</p>
</p>
<table>
<thead>
<tr>
<th>Value</th>
<th>Description</th>
</tr>
</thead>
<tbody><tr><td><p>&#34;Managed&#34;</p></td>
<td><p>IBMCloudKMSManagedAuth defines the KMS authentication strategy where the IKS/ROKS platform uses
service to service auth to call IBM Cloud KMS APIs (no customer credentials requried)</p>
</td>
</tr><tr><td><p>&#34;Unmanaged&#34;</p></td>
<td><p>IBMCloudKMSUnmanagedAuth defines the KMS authentication strategy where a customer supplies IBM Cloud
authentication to interact with IBM Cloud KMS APIs</p>
</td>
</tr></tbody>
</table>
###IBMCloudKMSKeyEntry { #hypershift.openshift.io/v1alpha1.IBMCloudKMSKeyEntry }
<p>
(<em>Appears on:</em>
<a href="#hypershift.openshift.io/v1alpha1.IBMCloudKMSSpec">IBMCloudKMSSpec</a>)
</p>
<p>
<p>IBMCloudKMSKeyEntry defines metadata for an IBM Cloud KMS encryption key</p>
</p>
<table>
<thead>
<tr>
<th>Field</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<code>crkID</code></br>
<em>
string
</em>
</td>
<td>
<p>CRKID is the customer rook key id</p>
</td>
</tr>
<tr>
<td>
<code>instanceID</code></br>
<em>
string
</em>
</td>
<td>
<p>InstanceID is the id for the key protect instance</p>
</td>
</tr>
<tr>
<td>
<code>correlationID</code></br>
<em>
string
</em>
</td>
<td>
<p>CorrelationID is an identifier used to track all api call usage from hypershift</p>
</td>
</tr>
<tr>
<td>
<code>url</code></br>
<em>
string
</em>
</td>
<td>
<p>URL is the url to call key protect apis over</p>
</td>
</tr>
<tr>
<td>
<code>keyVersion</code></br>
<em>
int
</em>
</td>
<td>
<p>KeyVersion is a unique number associated with the key. The number increments whenever a new
key is enabled for data encryption.</p>
</td>
</tr>
</tbody>
</table>
###IBMCloudKMSManagedAuthSpec { #hypershift.openshift.io/v1alpha1.IBMCloudKMSManagedAuthSpec }
<p>
(<em>Appears on:</em>
<a href="#hypershift.openshift.io/v1alpha1.IBMCloudKMSAuthSpec">IBMCloudKMSAuthSpec</a>)
</p>
<p>
<p>IBMCloudKMSManagedAuthSpec defines metadata around the service to service authentication strategy for the IBM Cloud
KMS system (all provider managed).</p>
</p>
###IBMCloudKMSSpec { #hypershift.openshift.io/v1alpha1.IBMCloudKMSSpec }
<p>
(<em>Appears on:</em>
<a href="#hypershift.openshift.io/v1alpha1.KMSSpec">KMSSpec</a>)
</p>
<p>
<p>IBMCloudKMSSpec defines metadata for the IBM Cloud KMS encryption strategy</p>
</p>
<table>
<thead>
<tr>
<th>Field</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<code>region</code></br>
<em>
string
</em>
</td>
<td>
<p>Region is the IBM Cloud region</p>
</td>
</tr>
<tr>
<td>
<code>auth</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.IBMCloudKMSAuthSpec">
IBMCloudKMSAuthSpec
</a>
</em>
</td>
<td>
<p>Auth defines metadata for how authentication is done with IBM Cloud KMS</p>
</td>
</tr>
<tr>
<td>
<code>keyList</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.IBMCloudKMSKeyEntry">
[]IBMCloudKMSKeyEntry
</a>
</em>
</td>
<td>
<p>KeyList defines the list of keys used for data encryption</p>
</td>
</tr>
</tbody>
</table>
###IBMCloudKMSUnmanagedAuthSpec { #hypershift.openshift.io/v1alpha1.IBMCloudKMSUnmanagedAuthSpec }
<p>
(<em>Appears on:</em>
<a href="#hypershift.openshift.io/v1alpha1.IBMCloudKMSAuthSpec">IBMCloudKMSAuthSpec</a>)
</p>
<p>
<p>IBMCloudKMSUnmanagedAuthSpec defines the auth metadata the customer provides to interact with IBM Cloud KMS</p>
</p>
<table>
<thead>
<tr>
<th>Field</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<code>credentials</code></br>
<em>
<a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.22/#localobjectreference-v1-core">
Kubernetes core/v1.LocalObjectReference
</a>
</em>
</td>
<td>
<p>Credentials should reference a secret with a key field of IBMCloudIAMAPIKeySecretKey that contains a apikey to
call IBM Cloud KMS APIs</p>
</td>
</tr>
</tbody>
</table>
###IBMCloudPlatformSpec { #hypershift.openshift.io/v1alpha1.IBMCloudPlatformSpec }
<p>
(<em>Appears on:</em>
<a href="#hypershift.openshift.io/v1alpha1.NodePoolPlatform">NodePoolPlatform</a>, 
<a href="#hypershift.openshift.io/v1alpha1.PlatformSpec">PlatformSpec</a>)
</p>
<p>
<p>IBMCloudPlatformSpec defines IBMCloud specific settings for components</p>
</p>
<table>
<thead>
<tr>
<th>Field</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<code>providerType</code></br>
<em>
<a href="https://docs.openshift.com/container-platform/4.10/rest_api/config_apis/config-apis-index.html">
github.com/openshift/api/config/v1.IBMCloudProviderType
</a>
</em>
</td>
<td>
<p>ProviderType is a specific supported infrastructure provider within IBM Cloud.</p>
</td>
</tr>
</tbody>
</table>
###ImageContentSource { #hypershift.openshift.io/v1alpha1.ImageContentSource }
<p>
(<em>Appears on:</em>
<a href="#hypershift.openshift.io/v1alpha1.HostedClusterSpec">HostedClusterSpec</a>, 
<a href="#hypershift.openshift.io/v1alpha1.HostedControlPlaneSpec">HostedControlPlaneSpec</a>)
</p>
<p>
<p>ImageContentSource specifies image mirrors that can be used by cluster nodes
to pull content. For cluster workloads, if a container image registry host of
the pullspec matches Source then one of the Mirrors are substituted as hosts
in the pullspec and tried in order to fetch the image.</p>
</p>
<table>
<thead>
<tr>
<th>Field</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<code>source</code></br>
<em>
string
</em>
</td>
<td>
<p>Source is the repository that users refer to, e.g. in image pull
specifications.</p>
</td>
</tr>
<tr>
<td>
<code>mirrors</code></br>
<em>
[]string
</em>
</td>
<td>
<em>(Optional)</em>
<p>Mirrors are one or more repositories that may also contain the same images.</p>
</td>
</tr>
</tbody>
</table>
###InPlaceUpgrade { #hypershift.openshift.io/v1alpha1.InPlaceUpgrade }
<p>
(<em>Appears on:</em>
<a href="#hypershift.openshift.io/v1alpha1.NodePoolManagement">NodePoolManagement</a>)
</p>
<p>
<p>InPlaceUpgrade specifies an upgrade strategy which upgrades nodes in-place
without any new nodes being created or any old nodes being deleted.</p>
</p>
###KMSProvider { #hypershift.openshift.io/v1alpha1.KMSProvider }
<p>
(<em>Appears on:</em>
<a href="#hypershift.openshift.io/v1alpha1.KMSSpec">KMSSpec</a>)
</p>
<p>
<p>KMSProvider defines the supported KMS providers</p>
</p>
<table>
<thead>
<tr>
<th>Value</th>
<th>Description</th>
</tr>
</thead>
<tbody><tr><td><p>&#34;AWS&#34;</p></td>
<td></td>
</tr><tr><td><p>&#34;IBMCloud&#34;</p></td>
<td></td>
</tr></tbody>
</table>
###KMSSpec { #hypershift.openshift.io/v1alpha1.KMSSpec }
<p>
(<em>Appears on:</em>
<a href="#hypershift.openshift.io/v1alpha1.SecretEncryptionSpec">SecretEncryptionSpec</a>)
</p>
<p>
<p>KMSSpec defines metadata about the kms secret encryption strategy</p>
</p>
<table>
<thead>
<tr>
<th>Field</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<code>provider</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.KMSProvider">
KMSProvider
</a>
</em>
</td>
<td>
<p>Provider defines the KMS provider</p>
<p>
Value must be one of:
&#34;AWS&#34;, 
&#34;IBMCloud&#34;
</p>
</td>
</tr>
<tr>
<td>
<code>ibmcloud</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.IBMCloudKMSSpec">
IBMCloudKMSSpec
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>IBMCloud defines metadata for the IBM Cloud KMS encryption strategy</p>
</td>
</tr>
<tr>
<td>
<code>aws</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.AWSKMSSpec">
AWSKMSSpec
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>AWS defines metadata about the configuration of the AWS KMS Secret Encryption provider</p>
</td>
</tr>
</tbody>
</table>
###KubevirtCompute { #hypershift.openshift.io/v1alpha1.KubevirtCompute }
<p>
(<em>Appears on:</em>
<a href="#hypershift.openshift.io/v1alpha1.KubevirtNodePoolPlatform">KubevirtNodePoolPlatform</a>)
</p>
<p>
<p>KubevirtCompute contains values associated with the virtual compute hardware requested for the VM.</p>
</p>
<table>
<thead>
<tr>
<th>Field</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<code>memory</code></br>
<em>
<a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.22/#quantity-resource-api">
k8s.io/apimachinery/pkg/api/resource.Quantity
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>Memory represents how much guest memory the VM should have</p>
</td>
</tr>
<tr>
<td>
<code>cores</code></br>
<em>
uint32
</em>
</td>
<td>
<em>(Optional)</em>
<p>Cores represents how many cores the guest VM should have</p>
</td>
</tr>
</tbody>
</table>
###KubevirtDiskImage { #hypershift.openshift.io/v1alpha1.KubevirtDiskImage }
<p>
(<em>Appears on:</em>
<a href="#hypershift.openshift.io/v1alpha1.KubevirtRootVolume">KubevirtRootVolume</a>)
</p>
<p>
<p>KubevirtDiskImage contains values representing where the rhcos image is located</p>
</p>
<table>
<thead>
<tr>
<th>Field</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<code>containerDiskImage</code></br>
<em>
string
</em>
</td>
<td>
<em>(Optional)</em>
<p>ContainerDiskImage is a string representing the container image that holds the root disk</p>
</td>
</tr>
</tbody>
</table>
###KubevirtNodePoolPlatform { #hypershift.openshift.io/v1alpha1.KubevirtNodePoolPlatform }
<p>
(<em>Appears on:</em>
<a href="#hypershift.openshift.io/v1alpha1.NodePoolPlatform">NodePoolPlatform</a>)
</p>
<p>
<p>KubevirtNodePoolPlatform specifies the configuration of a NodePool when operating
on KubeVirt platform.</p>
</p>
<table>
<thead>
<tr>
<th>Field</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<code>rootVolume</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.KubevirtRootVolume">
KubevirtRootVolume
</a>
</em>
</td>
<td>
<p>RootVolume represents values associated with the VM volume that will host rhcos</p>
</td>
</tr>
<tr>
<td>
<code>compute</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.KubevirtCompute">
KubevirtCompute
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>Compute contains values representing the virtual hardware requested for the VM</p>
</td>
</tr>
</tbody>
</table>
###KubevirtPersistentVolume { #hypershift.openshift.io/v1alpha1.KubevirtPersistentVolume }
<p>
(<em>Appears on:</em>
<a href="#hypershift.openshift.io/v1alpha1.KubevirtVolume">KubevirtVolume</a>)
</p>
<p>
<p>KubevirtPersistentVolume contains the values involved with provisioning persistent storage for a KubeVirt VM.</p>
</p>
<table>
<thead>
<tr>
<th>Field</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<code>size</code></br>
<em>
<a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.22/#quantity-resource-api">
k8s.io/apimachinery/pkg/api/resource.Quantity
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>Size is the size of the persistent storage volume</p>
</td>
</tr>
<tr>
<td>
<code>storageClass</code></br>
<em>
string
</em>
</td>
<td>
<em>(Optional)</em>
<p>StorageClass is the storageClass used for the underlying PVC that hosts the volume</p>
</td>
</tr>
<tr>
<td>
<code>accessModes</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.PersistentVolumeAccessMode">
[]PersistentVolumeAccessMode
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>AccessModes is an array that contains the desired Access Modes the root volume should have.
More info: <a href="https://kubernetes.io/docs/concepts/storage/persistent-volumes/#access-modes">https://kubernetes.io/docs/concepts/storage/persistent-volumes/#access-modes</a></p>
</td>
</tr>
</tbody>
</table>
###KubevirtRootVolume { #hypershift.openshift.io/v1alpha1.KubevirtRootVolume }
<p>
(<em>Appears on:</em>
<a href="#hypershift.openshift.io/v1alpha1.KubevirtNodePoolPlatform">KubevirtNodePoolPlatform</a>)
</p>
<p>
<p>KubevirtRootVolume represents the volume that the rhcos disk will be stored and run from.</p>
</p>
<table>
<thead>
<tr>
<th>Field</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<code>diskImage</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.KubevirtDiskImage">
KubevirtDiskImage
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>Image represents what rhcos image to use for the node pool</p>
</td>
</tr>
<tr>
<td>
<code>KubevirtVolume</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.KubevirtVolume">
KubevirtVolume
</a>
</em>
</td>
<td>
<p>
(Members of <code>KubevirtVolume</code> are embedded into this type.)
</p>
<p>KubevirtVolume represents of type of storage to run the image on</p>
</td>
</tr>
</tbody>
</table>
###KubevirtVolume { #hypershift.openshift.io/v1alpha1.KubevirtVolume }
<p>
(<em>Appears on:</em>
<a href="#hypershift.openshift.io/v1alpha1.KubevirtRootVolume">KubevirtRootVolume</a>)
</p>
<p>
<p>KubevirtVolume represents what kind of storage to use for a KubeVirt VM volume</p>
</p>
<table>
<thead>
<tr>
<th>Field</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<code>type</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.KubevirtVolumeType">
KubevirtVolumeType
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>Type represents the type of storage to associate with the kubevirt VMs.</p>
<p>
Value must be one of:
&#34;Persistent&#34;
</p>
</td>
</tr>
<tr>
<td>
<code>persistent</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.KubevirtPersistentVolume">
KubevirtPersistentVolume
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>Persistent volume type means the VM&rsquo;s storage is backed by a PVC
VMs that use persistent volumes can survive disruption events like restart and eviction
This is the default type used when no storage type is defined.</p>
</td>
</tr>
</tbody>
</table>
###KubevirtVolumeType { #hypershift.openshift.io/v1alpha1.KubevirtVolumeType }
<p>
(<em>Appears on:</em>
<a href="#hypershift.openshift.io/v1alpha1.KubevirtVolume">KubevirtVolume</a>)
</p>
<p>
<p>KubevirtVolumeType is a specific supported KubeVirt volumes</p>
</p>
<table>
<thead>
<tr>
<th>Value</th>
<th>Description</th>
</tr>
</thead>
<tbody><tr><td><p>&#34;Persistent&#34;</p></td>
<td><p>KubevirtVolumeTypePersistent represents persistent volume for kubevirt VMs</p>
</td>
</tr></tbody>
</table>
###LoadBalancerPublishingStrategy { #hypershift.openshift.io/v1alpha1.LoadBalancerPublishingStrategy }
<p>
(<em>Appears on:</em>
<a href="#hypershift.openshift.io/v1alpha1.ServicePublishingStrategy">ServicePublishingStrategy</a>)
</p>
<p>
<p>LoadBalancerPublishingStrategy specifies setting used to expose a service as a LoadBalancer.</p>
</p>
<table>
<thead>
<tr>
<th>Field</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<code>hostname</code></br>
<em>
string
</em>
</td>
<td>
<em>(Optional)</em>
<p>Hostname is the name of the DNS record that will be created pointing to the LoadBalancer.</p>
</td>
</tr>
</tbody>
</table>
###MachineNetworkEntry { #hypershift.openshift.io/v1alpha1.MachineNetworkEntry }
<p>
(<em>Appears on:</em>
<a href="#hypershift.openshift.io/v1alpha1.ClusterNetworking">ClusterNetworking</a>)
</p>
<p>
<p>MachineNetworkEntry is a single IP address block for node IP blocks.</p>
</p>
<table>
<thead>
<tr>
<th>Field</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<code>cidr</code></br>
<em>
<a href="#">
github.com/openshift/hypershift/api/util/ipnet.IPNet
</a>
</em>
</td>
<td>
<p>CIDR is the IP block address pool for machines within the cluster.</p>
</td>
</tr>
</tbody>
</table>
###ManagedEtcdSpec { #hypershift.openshift.io/v1alpha1.ManagedEtcdSpec }
<p>
(<em>Appears on:</em>
<a href="#hypershift.openshift.io/v1alpha1.EtcdSpec">EtcdSpec</a>)
</p>
<p>
<p>ManagedEtcdSpec specifies the behavior of an etcd cluster managed by
HyperShift.</p>
</p>
<table>
<thead>
<tr>
<th>Field</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<code>storage</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.ManagedEtcdStorageSpec">
ManagedEtcdStorageSpec
</a>
</em>
</td>
<td>
<p>Storage specifies how etcd data is persisted.</p>
</td>
</tr>
</tbody>
</table>
###ManagedEtcdStorageSpec { #hypershift.openshift.io/v1alpha1.ManagedEtcdStorageSpec }
<p>
(<em>Appears on:</em>
<a href="#hypershift.openshift.io/v1alpha1.ManagedEtcdSpec">ManagedEtcdSpec</a>)
</p>
<p>
<p>ManagedEtcdStorageSpec describes the storage configuration for etcd data.</p>
</p>
<table>
<thead>
<tr>
<th>Field</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<code>type</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.ManagedEtcdStorageType">
ManagedEtcdStorageType
</a>
</em>
</td>
<td>
<p>Type is the kind of persistent storage implementation to use for etcd.</p>
<p>
Value must be one of:
&#34;PersistentVolume&#34;
</p>
</td>
</tr>
<tr>
<td>
<code>persistentVolume</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.PersistentVolumeEtcdStorageSpec">
PersistentVolumeEtcdStorageSpec
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>PersistentVolume is the configuration for PersistentVolume etcd storage.
With this implementation, a PersistentVolume will be allocated for every
etcd member (either 1 or 3 depending on the HostedCluster control plane
availability configuration).</p>
</td>
</tr>
<tr>
<td>
<code>restoreSnapshotURL</code></br>
<em>
[]string
</em>
</td>
<td>
<em>(Optional)</em>
<p>RestoreSnapshotURL allows an optional list of URLs to be provided where
an etcd snapshot can be downloaded, for example a pre-signed URL
referencing a storage service, one URL per replica.
This snapshot will be restored on initial startup, only when the etcd PV
is empty.</p>
</td>
</tr>
</tbody>
</table>
###ManagedEtcdStorageType { #hypershift.openshift.io/v1alpha1.ManagedEtcdStorageType }
<p>
(<em>Appears on:</em>
<a href="#hypershift.openshift.io/v1alpha1.ManagedEtcdStorageSpec">ManagedEtcdStorageSpec</a>)
</p>
<p>
<p>ManagedEtcdStorageType is a storage type for an etcd cluster.</p>
</p>
<table>
<thead>
<tr>
<th>Value</th>
<th>Description</th>
</tr>
</thead>
<tbody><tr><td><p>&#34;PersistentVolume&#34;</p></td>
<td><p>PersistentVolumeEtcdStorage uses PersistentVolumes for etcd storage.</p>
</td>
</tr></tbody>
</table>
###NetworkType { #hypershift.openshift.io/v1alpha1.NetworkType }
<p>
(<em>Appears on:</em>
<a href="#hypershift.openshift.io/v1alpha1.ClusterNetworking">ClusterNetworking</a>, 
<a href="#hypershift.openshift.io/v1alpha1.HostedControlPlaneSpec">HostedControlPlaneSpec</a>)
</p>
<p>
<p>NetworkType specifies the SDN provider used for cluster networking.</p>
</p>
<table>
<thead>
<tr>
<th>Value</th>
<th>Description</th>
</tr>
</thead>
<tbody><tr><td><p>&#34;Calico&#34;</p></td>
<td><p>Calico specifies Calico as the SDN provider</p>
</td>
</tr><tr><td><p>&#34;OVNKubernetes&#34;</p></td>
<td><p>OVNKubernetes specifies OVN as the SDN provider</p>
</td>
</tr><tr><td><p>&#34;OpenShiftSDN&#34;</p></td>
<td><p>OpenShiftSDN specifies OpenShiftSDN as the SDN provider</p>
</td>
</tr><tr><td><p>&#34;Other&#34;</p></td>
<td><p>Other specifies an undefined SDN provider</p>
</td>
</tr></tbody>
</table>
###NodePoolAutoScaling { #hypershift.openshift.io/v1alpha1.NodePoolAutoScaling }
<p>
(<em>Appears on:</em>
<a href="#hypershift.openshift.io/v1alpha1.NodePoolSpec">NodePoolSpec</a>)
</p>
<p>
<p>NodePoolAutoScaling specifies auto-scaling behavior for a NodePool.</p>
</p>
<table>
<thead>
<tr>
<th>Field</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<code>min</code></br>
<em>
int32
</em>
</td>
<td>
<p>Min is the minimum number of nodes to maintain in the pool. Must be &gt;= 1.</p>
</td>
</tr>
<tr>
<td>
<code>max</code></br>
<em>
int32
</em>
</td>
<td>
<p>Max is the maximum number of nodes allowed in the pool. Must be &gt;= 1.</p>
</td>
</tr>
</tbody>
</table>
###NodePoolCondition { #hypershift.openshift.io/v1alpha1.NodePoolCondition }
<p>
(<em>Appears on:</em>
<a href="#hypershift.openshift.io/v1alpha1.NodePoolStatus">NodePoolStatus</a>)
</p>
<p>
<p>We define our own condition type since metav1.Condition has validation
for Reason that might be broken by what we bubble up from CAPI.
NodePoolCondition defines an observation of NodePool resource operational state.</p>
</p>
<table>
<thead>
<tr>
<th>Field</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<code>type</code></br>
<em>
string
</em>
</td>
<td>
<p>Type of condition in CamelCase or in foo.example.com/CamelCase.
Many .condition.type values are consistent across resources like Available, but because arbitrary conditions
can be useful (see .node.status.conditions), the ability to deconflict is important.</p>
</td>
</tr>
<tr>
<td>
<code>status</code></br>
<em>
<a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.22/#conditionstatus-v1-core">
Kubernetes core/v1.ConditionStatus
</a>
</em>
</td>
<td>
<p>Status of the condition, one of True, False, Unknown.</p>
</td>
</tr>
<tr>
<td>
<code>severity</code></br>
<em>
string
</em>
</td>
<td>
<em>(Optional)</em>
<p>Severity provides an explicit classification of Reason code, so the users or machines can immediately
understand the current situation and act accordingly.
The Severity field MUST be set only when Status=False.</p>
</td>
</tr>
<tr>
<td>
<code>lastTransitionTime</code></br>
<em>
<a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.22/#time-v1-meta">
Kubernetes meta/v1.Time
</a>
</em>
</td>
<td>
<p>Last time the condition transitioned from one status to another.
This should be when the underlying condition changed. If that is not known, then using the time when
the API field changed is acceptable.</p>
</td>
</tr>
<tr>
<td>
<code>reason</code></br>
<em>
string
</em>
</td>
<td>
<em>(Optional)</em>
<p>The reason for the condition&rsquo;s last transition in CamelCase.
The specific API may choose whether or not this field is considered a guaranteed API.
This field may not be empty.</p>
</td>
</tr>
<tr>
<td>
<code>message</code></br>
<em>
string
</em>
</td>
<td>
<em>(Optional)</em>
<p>A human readable message indicating details about the transition.
This field may be empty.</p>
</td>
</tr>
<tr>
<td>
<code>observedGeneration</code></br>
<em>
int64
</em>
</td>
<td>
</td>
</tr>
</tbody>
</table>
###NodePoolManagement { #hypershift.openshift.io/v1alpha1.NodePoolManagement }
<p>
(<em>Appears on:</em>
<a href="#hypershift.openshift.io/v1alpha1.NodePoolSpec">NodePoolSpec</a>)
</p>
<p>
<p>NodePoolManagement specifies behavior for managing nodes in a NodePool, such
as upgrade strategies and auto-repair behaviors.</p>
</p>
<table>
<thead>
<tr>
<th>Field</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<code>upgradeType</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.UpgradeType">
UpgradeType
</a>
</em>
</td>
<td>
<p>UpgradeType specifies the type of strategy for handling upgrades.</p>
<p>
Value must be one of:
&#34;InPlace&#34;, 
&#34;Replace&#34;
</p>
</td>
</tr>
<tr>
<td>
<code>replace</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.ReplaceUpgrade">
ReplaceUpgrade
</a>
</em>
</td>
<td>
<p>Replace is the configuration for rolling upgrades.</p>
</td>
</tr>
<tr>
<td>
<code>inPlace</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.InPlaceUpgrade">
InPlaceUpgrade
</a>
</em>
</td>
<td>
<p>InPlace is the configuration for in-place upgrades.</p>
</td>
</tr>
<tr>
<td>
<code>autoRepair</code></br>
<em>
bool
</em>
</td>
<td>
<em>(Optional)</em>
<p>AutoRepair specifies whether health checks should be enabled for machines
in the NodePool. The default is false.</p>
</td>
</tr>
</tbody>
</table>
###NodePoolPlatform { #hypershift.openshift.io/v1alpha1.NodePoolPlatform }
<p>
(<em>Appears on:</em>
<a href="#hypershift.openshift.io/v1alpha1.NodePoolSpec">NodePoolSpec</a>)
</p>
<p>
<p>NodePoolPlatform specifies the underlying infrastructure provider for the
NodePool and is used to configure platform specific behavior.</p>
</p>
<table>
<thead>
<tr>
<th>Field</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<code>type</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.PlatformType">
PlatformType
</a>
</em>
</td>
<td>
<p>Type specifies the platform name.</p>
<p>
Value must be one of:
&#34;AWS&#34;, 
&#34;Agent&#34;, 
&#34;Azure&#34;, 
&#34;IBMCloud&#34;, 
&#34;KubeVirt&#34;, 
&#34;None&#34;, 
&#34;PowerVS&#34;
</p>
</td>
</tr>
<tr>
<td>
<code>aws</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.AWSNodePoolPlatform">
AWSNodePoolPlatform
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>AWS specifies the configuration used when operating on AWS.</p>
</td>
</tr>
<tr>
<td>
<code>ibmcloud</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.IBMCloudPlatformSpec">
IBMCloudPlatformSpec
</a>
</em>
</td>
<td>
<p>IBMCloud defines IBMCloud specific settings for components</p>
</td>
</tr>
<tr>
<td>
<code>kubevirt</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.KubevirtNodePoolPlatform">
KubevirtNodePoolPlatform
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>Kubevirt specifies the configuration used when operating on KubeVirt platform.</p>
</td>
</tr>
<tr>
<td>
<code>agent</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.AgentNodePoolPlatform">
AgentNodePoolPlatform
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>Agent specifies the configuration used when using Agent platform.</p>
</td>
</tr>
<tr>
<td>
<code>azure</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.AzureNodePoolPlatform">
AzureNodePoolPlatform
</a>
</em>
</td>
<td>
</td>
</tr>
<tr>
<td>
<code>powervs</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.PowerVSNodePoolPlatform">
PowerVSNodePoolPlatform
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>PowerVS specifies the configuration used when using IBMCloud PowerVS platform.</p>
</td>
</tr>
</tbody>
</table>
###NodePoolSpec { #hypershift.openshift.io/v1alpha1.NodePoolSpec }
<p>
(<em>Appears on:</em>
<a href="#hypershift.openshift.io/v1alpha1.NodePool">NodePool</a>)
</p>
<p>
<p>NodePoolSpec is the desired behavior of a NodePool.</p>
</p>
<table>
<thead>
<tr>
<th>Field</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<code>clusterName</code></br>
<em>
string
</em>
</td>
<td>
<p>ClusterName is the name of the HostedCluster this NodePool belongs to.</p>
<p>TODO(dan): Should this be a LocalObjectReference?</p>
</td>
</tr>
<tr>
<td>
<code>release</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.Release">
Release
</a>
</em>
</td>
<td>
<p>Release specifies the OCP release used for the NodePool. This informs the
ignition configuration for machines, as well as other platform specific
machine properties (e.g. an AMI on the AWS platform).</p>
</td>
</tr>
<tr>
<td>
<code>platform</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.NodePoolPlatform">
NodePoolPlatform
</a>
</em>
</td>
<td>
<p>Platform specifies the underlying infrastructure provider for the NodePool
and is used to configure platform specific behavior.</p>
</td>
</tr>
<tr>
<td>
<code>nodeCount</code></br>
<em>
int32
</em>
</td>
<td>
<em>(Optional)</em>
<p>Deprecated: Use Replicas instead. NodeCount will be dropped in the next
api release.</p>
</td>
</tr>
<tr>
<td>
<code>replicas</code></br>
<em>
int32
</em>
</td>
<td>
<em>(Optional)</em>
<p>Replicas is the desired number of nodes the pool should maintain. If
unset, the default value is 0.</p>
</td>
</tr>
<tr>
<td>
<code>management</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.NodePoolManagement">
NodePoolManagement
</a>
</em>
</td>
<td>
<p>Management specifies behavior for managing nodes in the pool, such as
upgrade strategies and auto-repair behaviors.</p>
</td>
</tr>
<tr>
<td>
<code>autoScaling</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.NodePoolAutoScaling">
NodePoolAutoScaling
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>Autoscaling specifies auto-scaling behavior for the NodePool.</p>
</td>
</tr>
<tr>
<td>
<code>config</code></br>
<em>
<a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.22/#localobjectreference-v1-core">
[]Kubernetes core/v1.LocalObjectReference
</a>
</em>
</td>
<td>
<p>Config is a list of references to ConfigMaps containing serialized
MachineConfig resources to be injected into the ignition configurations of
nodes in the NodePool. The MachineConfig API schema is defined here:</p>
<p><a href="https://github.com/openshift/machine-config-operator/blob/18963e4f8fe66e8c513ca4b131620760a414997f/pkg/apis/machineconfiguration.openshift.io/v1/types.go#L185">https://github.com/openshift/machine-config-operator/blob/18963e4f8fe66e8c513ca4b131620760a414997f/pkg/apis/machineconfiguration.openshift.io/v1/types.go#L185</a></p>
<p>Each ConfigMap must have a single key named &ldquo;config&rdquo; whose value is the
JSON or YAML of a serialized MachineConfig.</p>
</td>
</tr>
<tr>
<td>
<code>nodeDrainTimeout</code></br>
<em>
<a href="https://godoc.org/k8s.io/apimachinery/pkg/apis/meta/v1#Duration">
Kubernetes meta/v1.Duration
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>NodeDrainTimeout is the total amount of time that the controller will spend on draining a node.
The default value is 0, meaning that the node can be drained without any time limitations.
NOTE: NodeDrainTimeout is different from <code>kubectl drain --timeout</code>
TODO (alberto): Today changing this field will trigger a recreate rolling update, which kind of defeats
the purpose of the change. In future we plan to propagate this field in-place.
<a href="https://github.com/kubernetes-sigs/cluster-api/issues/5880">https://github.com/kubernetes-sigs/cluster-api/issues/5880</a></p>
</td>
</tr>
<tr>
<td>
<code>pausedUntil</code></br>
<em>
string
</em>
</td>
<td>
<em>(Optional)</em>
<p>PausedUntil is a field that can be used to pause reconciliation on a resource.
Either a date can be provided in RFC3339 format or a boolean. If a date is
provided: reconciliation is paused on the resource until that date. If the boolean true is
provided: reconciliation is paused on the resource until the field is removed.</p>
</td>
</tr>
</tbody>
</table>
###NodePoolStatus { #hypershift.openshift.io/v1alpha1.NodePoolStatus }
<p>
(<em>Appears on:</em>
<a href="#hypershift.openshift.io/v1alpha1.NodePool">NodePool</a>)
</p>
<p>
<p>NodePoolStatus is the latest observed status of a NodePool.</p>
</p>
<table>
<thead>
<tr>
<th>Field</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<code>replicas</code></br>
<em>
int32
</em>
</td>
<td>
<em>(Optional)</em>
<p>Replicas is the latest observed number of nodes in the pool.</p>
</td>
</tr>
<tr>
<td>
<code>version</code></br>
<em>
string
</em>
</td>
<td>
<p>Version is the semantic version of the latest applied release specified by
the NodePool.</p>
</td>
</tr>
<tr>
<td>
<code>conditions</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.NodePoolCondition">
[]NodePoolCondition
</a>
</em>
</td>
<td>
<p>Conditions represents the latest available observations of the node pool&rsquo;s
current state.</p>
</td>
</tr>
</tbody>
</table>
###NodePortPublishingStrategy { #hypershift.openshift.io/v1alpha1.NodePortPublishingStrategy }
<p>
(<em>Appears on:</em>
<a href="#hypershift.openshift.io/v1alpha1.ServicePublishingStrategy">ServicePublishingStrategy</a>)
</p>
<p>
<p>NodePortPublishingStrategy specifies a NodePort used to expose a service.</p>
</p>
<table>
<thead>
<tr>
<th>Field</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<code>address</code></br>
<em>
string
</em>
</td>
<td>
<p>Address is the host/ip that the NodePort service is exposed over.</p>
</td>
</tr>
<tr>
<td>
<code>port</code></br>
<em>
int32
</em>
</td>
<td>
<p>Port is the port of the NodePort service. If &lt;=0, the port is dynamically
assigned when the service is created.</p>
</td>
</tr>
</tbody>
</table>
###OLMCatalogPlacement { #hypershift.openshift.io/v1alpha1.OLMCatalogPlacement }
<p>
(<em>Appears on:</em>
<a href="#hypershift.openshift.io/v1alpha1.HostedClusterSpec">HostedClusterSpec</a>, 
<a href="#hypershift.openshift.io/v1alpha1.HostedControlPlaneSpec">HostedControlPlaneSpec</a>)
</p>
<p>
<p>OLMCatalogPlacement is an enum specifying the placement of OLM catalog components.</p>
</p>
<table>
<thead>
<tr>
<th>Value</th>
<th>Description</th>
</tr>
</thead>
<tbody><tr><td><p>&#34;guest&#34;</p></td>
<td><p>GuestOLMCatalogPlacement indicates OLM catalog components will be placed in
the guest cluster.</p>
</td>
</tr><tr><td><p>&#34;management&#34;</p></td>
<td><p>ManagementOLMCatalogPlacement indicates OLM catalog components will be placed in
the management cluster.</p>
</td>
</tr></tbody>
</table>
###PersistentVolumeAccessMode { #hypershift.openshift.io/v1alpha1.PersistentVolumeAccessMode }
<p>
(<em>Appears on:</em>
<a href="#hypershift.openshift.io/v1alpha1.KubevirtPersistentVolume">KubevirtPersistentVolume</a>)
</p>
<p>
</p>
###PersistentVolumeEtcdStorageSpec { #hypershift.openshift.io/v1alpha1.PersistentVolumeEtcdStorageSpec }
<p>
(<em>Appears on:</em>
<a href="#hypershift.openshift.io/v1alpha1.ManagedEtcdStorageSpec">ManagedEtcdStorageSpec</a>)
</p>
<p>
<p>PersistentVolumeEtcdStorageSpec is the configuration for PersistentVolume
etcd storage.</p>
</p>
<table>
<thead>
<tr>
<th>Field</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<code>storageClassName</code></br>
<em>
string
</em>
</td>
<td>
<em>(Optional)</em>
<p>StorageClassName is the StorageClass of the data volume for each etcd member.</p>
<p>See <a href="https://kubernetes.io/docs/concepts/storage/persistent-volumes#class-1">https://kubernetes.io/docs/concepts/storage/persistent-volumes#class-1</a>.</p>
</td>
</tr>
<tr>
<td>
<code>size</code></br>
<em>
<a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.22/#quantity-resource-api">
k8s.io/apimachinery/pkg/api/resource.Quantity
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>Size is the minimum size of the data volume for each etcd member.</p>
</td>
</tr>
</tbody>
</table>
###PlatformSpec { #hypershift.openshift.io/v1alpha1.PlatformSpec }
<p>
(<em>Appears on:</em>
<a href="#hypershift.openshift.io/v1alpha1.HostedClusterSpec">HostedClusterSpec</a>, 
<a href="#hypershift.openshift.io/v1alpha1.HostedControlPlaneSpec">HostedControlPlaneSpec</a>)
</p>
<p>
<p>PlatformSpec specifies the underlying infrastructure provider for the cluster
and is used to configure platform specific behavior.</p>
</p>
<table>
<thead>
<tr>
<th>Field</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<code>type</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.PlatformType">
PlatformType
</a>
</em>
</td>
<td>
<p>Type is the type of infrastructure provider for the cluster.</p>
<p>
Value must be one of:
&#34;AWS&#34;, 
&#34;Agent&#34;, 
&#34;Azure&#34;, 
&#34;IBMCloud&#34;, 
&#34;KubeVirt&#34;, 
&#34;None&#34;, 
&#34;PowerVS&#34;
</p>
</td>
</tr>
<tr>
<td>
<code>aws</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.AWSPlatformSpec">
AWSPlatformSpec
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>AWS specifies configuration for clusters running on Amazon Web Services.</p>
</td>
</tr>
<tr>
<td>
<code>agent</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.AgentPlatformSpec">
AgentPlatformSpec
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>Agent specifies configuration for agent-based installations.</p>
</td>
</tr>
<tr>
<td>
<code>ibmcloud</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.IBMCloudPlatformSpec">
IBMCloudPlatformSpec
</a>
</em>
</td>
<td>
<p>IBMCloud defines IBMCloud specific settings for components</p>
</td>
</tr>
<tr>
<td>
<code>azure</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.AzurePlatformSpec">
AzurePlatformSpec
</a>
</em>
</td>
<td>
<p>Azure defines azure specific settings</p>
</td>
</tr>
<tr>
<td>
<code>powervs</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.PowerVSPlatformSpec">
PowerVSPlatformSpec
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>PowerVS specifies configuration for clusters running on IBMCloud Power VS Service.
This field is immutable. Once set, It can&rsquo;t be changed.</p>
</td>
</tr>
</tbody>
</table>
###PlatformType { #hypershift.openshift.io/v1alpha1.PlatformType }
<p>
(<em>Appears on:</em>
<a href="#hypershift.openshift.io/v1alpha1.NodePoolPlatform">NodePoolPlatform</a>, 
<a href="#hypershift.openshift.io/v1alpha1.PlatformSpec">PlatformSpec</a>)
</p>
<p>
<p>PlatformType is a specific supported infrastructure provider.</p>
</p>
<table>
<thead>
<tr>
<th>Value</th>
<th>Description</th>
</tr>
</thead>
<tbody><tr><td><p>&#34;AWS&#34;</p></td>
<td><p>AWSPlatform represents Amazon Web Services infrastructure.</p>
</td>
</tr><tr><td><p>&#34;Agent&#34;</p></td>
<td><p>AgentPlatform represents user supplied insfrastructure booted with agents.</p>
</td>
</tr><tr><td><p>&#34;Azure&#34;</p></td>
<td><p>AzurePlatform represents Azure infrastructure.</p>
</td>
</tr><tr><td><p>&#34;IBMCloud&#34;</p></td>
<td><p>IBMCloudPlatform represents IBM Cloud infrastructure.</p>
</td>
</tr><tr><td><p>&#34;KubeVirt&#34;</p></td>
<td><p>KubevirtPlatform represents Kubevirt infrastructure.</p>
</td>
</tr><tr><td><p>&#34;None&#34;</p></td>
<td><p>NonePlatform represents user supplied (e.g. bare metal) infrastructure.</p>
</td>
</tr><tr><td><p>&#34;PowerVS&#34;</p></td>
<td><p>PowerVSPlatform represents PowerVS infrastructure.</p>
</td>
</tr></tbody>
</table>
###PowerVSNodePoolPlatform { #hypershift.openshift.io/v1alpha1.PowerVSNodePoolPlatform }
<p>
(<em>Appears on:</em>
<a href="#hypershift.openshift.io/v1alpha1.NodePoolPlatform">NodePoolPlatform</a>)
</p>
<p>
<p>PowerVSNodePoolPlatform specifies the configuration of a NodePool when operating
on IBMCloud PowerVS platform.</p>
</p>
<table>
<thead>
<tr>
<th>Field</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<code>systemType</code></br>
<em>
string
</em>
</td>
<td>
<em>(Optional)</em>
<p>SystemType is the System type used to host the instance.
systemType determines the number of cores and memory that is available.
Few of the supported SystemTypes are s922,e880,e980.
e880 systemType available only in Dallas Datacenters.
e980 systemType available in Datacenters except Dallas and Washington.
When omitted, this means that the user has no opinion and the platform is left to choose a
reasonable default. The current default is s922 which is generally available.</p>
</td>
</tr>
<tr>
<td>
<code>processorType</code></br>
<em>
string
</em>
</td>
<td>
<em>(Optional)</em>
<p>ProcessorType is the VM instance processor type.
It must be set to one of the following values: Dedicated, Capped or Shared.</p>
<p>Dedicated: resources are allocated for a specific client, The hypervisor makes a 1:1 binding of a partitionâ€™s processor to a physical processor core.
Shared: Shared among other clients.
Capped: Shared, but resources do not expand beyond those that are requested, the amount of CPU time is Capped to the value specified for the entitlement.</p>
<p>if the processorType is selected as Dedicated, then Processors value cannot be fractional.
When omitted, this means that the user has no opinion and the platform is left to choose a
reasonable default. The current default is Shared.</p>
</td>
</tr>
<tr>
<td>
<code>processors</code></br>
<em>
<a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.22/#intorstring-intstr-util">
k8s.io/apimachinery/pkg/util/intstr.IntOrString
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>Processors is the number of virtual processors in a virtual machine.
when the processorType is selected as Dedicated the processors value cannot be fractional.
maximum value for the Processors depends on the selected SystemType.
when SystemType is set to e880 or e980 maximum Processors value is 143.
when SystemType is set to s922 maximum Processors value is 15.
minimum value for Processors depends on the selected ProcessorType.
when ProcessorType is set as Shared or Capped, The minimum processors is 0.5.
when ProcessorType is set as Dedicated, The minimum processors is 1.
When omitted, this means that the user has no opinion and the platform is left to choose a
reasonable default. The default is set based on the selected ProcessorType.
when ProcessorType selected as Dedicated, the default is set to 1.
when ProcessorType selected as Shared or Capped, the default is set to 0.5.</p>
</td>
</tr>
<tr>
<td>
<code>memoryGiB</code></br>
<em>
int32
</em>
</td>
<td>
<em>(Optional)</em>
<p>MemoryGiB is the size of a virtual machine&rsquo;s memory, in GiB.
maximum value for the MemoryGiB depends on the selected SystemType.
when SystemType is set to e880 maximum MemoryGiB value is 7463 GiB.
when SystemType is set to e980 maximum MemoryGiB value is 15307 GiB.
when SystemType is set to s922 maximum MemoryGiB value is 942 GiB.
The minimum memory is 32 GiB.</p>
<p>When omitted, this means the user has no opinion and the platform is left to choose a reasonable
default. The current default is 32.</p>
</td>
</tr>
<tr>
<td>
<code>image</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.PowerVSResourceReference">
PowerVSResourceReference
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>Image used for deploying the nodes. If unspecified, the default
is chosen based on the NodePool release payload image.</p>
</td>
</tr>
<tr>
<td>
<code>storageType</code></br>
<em>
string
</em>
</td>
<td>
<em>(Optional)</em>
<p>StorageType for the image and nodes, this will be ignored if Image is specified.
The storage tiers in PowerVS are based on I/O operations per second (IOPS).
It means that the performance of your storage volumes is limited to the maximum number of IOPS based on volume size and storage tier.
Although, the exact numbers might change over time, the Tier 3 storage is currently set to 3 IOPS/GB, and the Tier 1 storage is currently set to 10 IOPS/GB.</p>
<p>The default is tier1</p>
</td>
</tr>
<tr>
<td>
<code>imageDeletePolicy</code></br>
<em>
string
</em>
</td>
<td>
<em>(Optional)</em>
<p>ImageDeletePolicy is policy for the image deletion.</p>
<p>delete: delete the image from the infrastructure.
retain: delete the image from the openshift but retain in the infrastructure.</p>
<p>The default is delete</p>
</td>
</tr>
</tbody>
</table>
###PowerVSPlatformSpec { #hypershift.openshift.io/v1alpha1.PowerVSPlatformSpec }
<p>
(<em>Appears on:</em>
<a href="#hypershift.openshift.io/v1alpha1.PlatformSpec">PlatformSpec</a>)
</p>
<p>
<p>PowerVSPlatformSpec defines IBMCloud PowerVS specific settings for components</p>
</p>
<table>
<thead>
<tr>
<th>Field</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<code>accountID</code></br>
<em>
string
</em>
</td>
<td>
<p>AccountID is the IBMCloud account id.
This field is immutable. Once set, It can&rsquo;t be changed.</p>
</td>
</tr>
<tr>
<td>
<code>cisInstanceCRN</code></br>
<em>
string
</em>
</td>
<td>
<p>CISInstanceCRN is the IBMCloud CIS Service Instance&rsquo;s Cloud Resource Name
This field is immutable. Once set, It can&rsquo;t be changed.</p>
</td>
</tr>
<tr>
<td>
<code>resourceGroup</code></br>
<em>
string
</em>
</td>
<td>
<p>ResourceGroup is the IBMCloud Resource Group in which the cluster resides.
This field is immutable. Once set, It can&rsquo;t be changed.</p>
</td>
</tr>
<tr>
<td>
<code>region</code></br>
<em>
string
</em>
</td>
<td>
<p>Region is the IBMCloud region in which the cluster resides. This configures the
OCP control plane cloud integrations, and is used by NodePool to resolve
the correct boot image for a given release.
This field is immutable. Once set, It can&rsquo;t be changed.</p>
</td>
</tr>
<tr>
<td>
<code>zone</code></br>
<em>
string
</em>
</td>
<td>
<p>Zone is the availability zone where control plane cloud resources are
created.
This field is immutable. Once set, It can&rsquo;t be changed.</p>
</td>
</tr>
<tr>
<td>
<code>subnet</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.PowerVSResourceReference">
PowerVSResourceReference
</a>
</em>
</td>
<td>
<p>Subnet is the subnet to use for control plane cloud resources.
This field is immutable. Once set, It can&rsquo;t be changed.</p>
</td>
</tr>
<tr>
<td>
<code>serviceInstanceID</code></br>
<em>
string
</em>
</td>
<td>
<p>ServiceInstance is the reference to the Power VS service on which the server instance(VM) will be created.
Power VS service is a container for all Power VS instances at a specific geographic region.
serviceInstance can be created via IBM Cloud catalog or CLI.
ServiceInstanceID is the unique identifier that can be obtained from IBM Cloud UI or IBM Cloud cli.</p>
<p>More detail about Power VS service instance.
<a href="https://cloud.ibm.com/docs/power-iaas?topic=power-iaas-creating-power-virtual-server">https://cloud.ibm.com/docs/power-iaas?topic=power-iaas-creating-power-virtual-server</a></p>
<p>This field is immutable. Once set, It can&rsquo;t be changed.</p>
</td>
</tr>
<tr>
<td>
<code>vpc</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.PowerVSVPC">
PowerVSVPC
</a>
</em>
</td>
<td>
<p>VPC specifies IBM Cloud PowerVS Load Balancing configuration for the control
plane.
This field is immutable. Once set, It can&rsquo;t be changed.</p>
</td>
</tr>
<tr>
<td>
<code>kubeCloudControllerCreds</code></br>
<em>
<a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.22/#localobjectreference-v1-core">
Kubernetes core/v1.LocalObjectReference
</a>
</em>
</td>
<td>
<p>KubeCloudControllerCreds is a reference to a secret containing cloud
credentials with permissions matching the cloud controller policy.
This field is immutable. Once set, It can&rsquo;t be changed.</p>
<p>TODO(dan): document the &ldquo;cloud controller policy&rdquo;</p>
</td>
</tr>
<tr>
<td>
<code>nodePoolManagementCreds</code></br>
<em>
<a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.22/#localobjectreference-v1-core">
Kubernetes core/v1.LocalObjectReference
</a>
</em>
</td>
<td>
<p>NodePoolManagementCreds is a reference to a secret containing cloud
credentials with permissions matching the node pool management policy.
This field is immutable. Once set, It can&rsquo;t be changed.</p>
<p>TODO(dan): document the &ldquo;node pool management policy&rdquo;</p>
</td>
</tr>
<tr>
<td>
<code>controlPlaneOperatorCreds</code></br>
<em>
<a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.22/#localobjectreference-v1-core">
Kubernetes core/v1.LocalObjectReference
</a>
</em>
</td>
<td>
<p>ControlPlaneOperatorCreds is a reference to a secret containing cloud
credentials with permissions matching the control-plane-operator policy.
This field is immutable. Once set, It can&rsquo;t be changed.</p>
<p>TODO(dan): document the &ldquo;control plane operator policy&rdquo;</p>
</td>
</tr>
<tr>
<td>
<code>ingressOperatorCloudCreds</code></br>
<em>
<a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.22/#localobjectreference-v1-core">
Kubernetes core/v1.LocalObjectReference
</a>
</em>
</td>
<td>
<p>IngressOperatorCloudCreds is a reference to a secret containing ibm cloud
credentials for ingress operator to get authenticated with ibm cloud.</p>
</td>
</tr>
</tbody>
</table>
###PowerVSResourceReference { #hypershift.openshift.io/v1alpha1.PowerVSResourceReference }
<p>
(<em>Appears on:</em>
<a href="#hypershift.openshift.io/v1alpha1.PowerVSNodePoolPlatform">PowerVSNodePoolPlatform</a>, 
<a href="#hypershift.openshift.io/v1alpha1.PowerVSPlatformSpec">PowerVSPlatformSpec</a>)
</p>
<p>
<p>PowerVSResourceReference is a reference to a specific IBMCloud PowerVS resource by ID, or Name.
Only one of ID, or Name may be specified. Specifying more than one will result in
a validation error.</p>
</p>
<table>
<thead>
<tr>
<th>Field</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<code>id</code></br>
<em>
string
</em>
</td>
<td>
<em>(Optional)</em>
<p>ID of resource</p>
</td>
</tr>
<tr>
<td>
<code>name</code></br>
<em>
string
</em>
</td>
<td>
<em>(Optional)</em>
<p>Name of resource</p>
</td>
</tr>
</tbody>
</table>
###PowerVSVPC { #hypershift.openshift.io/v1alpha1.PowerVSVPC }
<p>
(<em>Appears on:</em>
<a href="#hypershift.openshift.io/v1alpha1.PowerVSPlatformSpec">PowerVSPlatformSpec</a>)
</p>
<p>
<p>PowerVSVPC specifies IBM Cloud PowerVS LoadBalancer configuration for the control
plane.</p>
</p>
<table>
<thead>
<tr>
<th>Field</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<code>name</code></br>
<em>
string
</em>
</td>
<td>
<p>Name for VPC to used for all the service load balancer.
This field is immutable. Once set, It can&rsquo;t be changed.</p>
</td>
</tr>
<tr>
<td>
<code>region</code></br>
<em>
string
</em>
</td>
<td>
<p>Region is the IBMCloud region in which VPC gets created, this VPC used for all the ingress traffic
into the OCP cluster.
This field is immutable. Once set, It can&rsquo;t be changed.</p>
</td>
</tr>
<tr>
<td>
<code>zone</code></br>
<em>
string
</em>
</td>
<td>
<em>(Optional)</em>
<p>Zone is the availability zone where load balancer cloud resources are
created.
This field is immutable. Once set, It can&rsquo;t be changed.</p>
</td>
</tr>
<tr>
<td>
<code>subnet</code></br>
<em>
string
</em>
</td>
<td>
<em>(Optional)</em>
<p>Subnet is the subnet to use for load balancer.
This field is immutable. Once set, It can&rsquo;t be changed.</p>
</td>
</tr>
</tbody>
</table>
###PublishingStrategyType { #hypershift.openshift.io/v1alpha1.PublishingStrategyType }
<p>
(<em>Appears on:</em>
<a href="#hypershift.openshift.io/v1alpha1.ServicePublishingStrategy">ServicePublishingStrategy</a>)
</p>
<p>
<p>PublishingStrategyType defines publishing strategies for services.</p>
</p>
###Release { #hypershift.openshift.io/v1alpha1.Release }
<p>
(<em>Appears on:</em>
<a href="#hypershift.openshift.io/v1alpha1.ClusterVersionStatus">ClusterVersionStatus</a>, 
<a href="#hypershift.openshift.io/v1alpha1.HostedClusterSpec">HostedClusterSpec</a>, 
<a href="#hypershift.openshift.io/v1alpha1.NodePoolSpec">NodePoolSpec</a>)
</p>
<p>
<p>Release represents the metadata for an OCP release payload image.</p>
</p>
<table>
<thead>
<tr>
<th>Field</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<code>image</code></br>
<em>
string
</em>
</td>
<td>
<p>Image is the image pullspec of an OCP release payload image.</p>
</td>
</tr>
</tbody>
</table>
###ReplaceUpgrade { #hypershift.openshift.io/v1alpha1.ReplaceUpgrade }
<p>
(<em>Appears on:</em>
<a href="#hypershift.openshift.io/v1alpha1.NodePoolManagement">NodePoolManagement</a>)
</p>
<p>
<p>ReplaceUpgrade specifies upgrade behavior that replaces existing nodes
according to a given strategy.</p>
</p>
<table>
<thead>
<tr>
<th>Field</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<code>strategy</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.UpgradeStrategy">
UpgradeStrategy
</a>
</em>
</td>
<td>
<p>Strategy is the node replacement strategy for nodes in the pool.</p>
<p>
Value must be one of:
&#34;OnDelete&#34;, 
&#34;RollingUpdate&#34;
</p>
</td>
</tr>
<tr>
<td>
<code>rollingUpdate</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.RollingUpdate">
RollingUpdate
</a>
</em>
</td>
<td>
<p>RollingUpdate specifies a rolling update strategy which upgrades nodes by
creating new nodes and deleting the old ones.</p>
</td>
</tr>
</tbody>
</table>
###RollingUpdate { #hypershift.openshift.io/v1alpha1.RollingUpdate }
<p>
(<em>Appears on:</em>
<a href="#hypershift.openshift.io/v1alpha1.ReplaceUpgrade">ReplaceUpgrade</a>)
</p>
<p>
<p>RollingUpdate specifies a rolling update strategy which upgrades nodes by
creating new nodes and deleting the old ones.</p>
</p>
<table>
<thead>
<tr>
<th>Field</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<code>maxUnavailable</code></br>
<em>
<a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.22/#intorstring-intstr-util">
k8s.io/apimachinery/pkg/util/intstr.IntOrString
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>MaxUnavailable is the maximum number of nodes that can be unavailable
during the update.</p>
<p>Value can be an absolute number (ex: 5) or a percentage of desired nodes
(ex: 10%).</p>
<p>Absolute number is calculated from percentage by rounding down.</p>
<p>This can not be 0 if MaxSurge is 0.</p>
<p>Defaults to 0.</p>
<p>Example: when this is set to 30%, old nodes can be deleted down to 70% of
desired nodes immediately when the rolling update starts. Once new nodes
are ready, more old nodes be deleted, followed by provisioning new nodes,
ensuring that the total number of nodes available at all times during the
update is at least 70% of desired nodes.</p>
</td>
</tr>
<tr>
<td>
<code>maxSurge</code></br>
<em>
<a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.22/#intorstring-intstr-util">
k8s.io/apimachinery/pkg/util/intstr.IntOrString
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>MaxSurge is the maximum number of nodes that can be provisioned above the
desired number of nodes.</p>
<p>Value can be an absolute number (ex: 5) or a percentage of desired nodes
(ex: 10%).</p>
<p>Absolute number is calculated from percentage by rounding up.</p>
<p>This can not be 0 if MaxUnavailable is 0.</p>
<p>Defaults to 1.</p>
<p>Example: when this is set to 30%, new nodes can be provisioned immediately
when the rolling update starts, such that the total number of old and new
nodes do not exceed 130% of desired nodes. Once old nodes have been
deleted, new nodes can be provisioned, ensuring that total number of nodes
running at any time during the update is at most 130% of desired nodes.</p>
</td>
</tr>
</tbody>
</table>
###RoutePublishingStrategy { #hypershift.openshift.io/v1alpha1.RoutePublishingStrategy }
<p>
(<em>Appears on:</em>
<a href="#hypershift.openshift.io/v1alpha1.ServicePublishingStrategy">ServicePublishingStrategy</a>)
</p>
<p>
<p>RoutePublishingStrategy specifies options for exposing a service as a Route.</p>
</p>
<table>
<thead>
<tr>
<th>Field</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<code>hostname</code></br>
<em>
string
</em>
</td>
<td>
<em>(Optional)</em>
<p>Hostname is the name of the DNS record that will be created pointing to the Route.</p>
</td>
</tr>
</tbody>
</table>
###SecretEncryptionSpec { #hypershift.openshift.io/v1alpha1.SecretEncryptionSpec }
<p>
(<em>Appears on:</em>
<a href="#hypershift.openshift.io/v1alpha1.HostedClusterSpec">HostedClusterSpec</a>, 
<a href="#hypershift.openshift.io/v1alpha1.HostedControlPlaneSpec">HostedControlPlaneSpec</a>)
</p>
<p>
<p>SecretEncryptionSpec contains metadata about the kubernetes secret encryption strategy being used for the
cluster when applicable.</p>
</p>
<table>
<thead>
<tr>
<th>Field</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<code>type</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.SecretEncryptionType">
SecretEncryptionType
</a>
</em>
</td>
<td>
<p>Type defines the type of kube secret encryption being used</p>
<p>
Value must be one of:
&#34;aescbc&#34;, 
&#34;kms&#34;
</p>
</td>
</tr>
<tr>
<td>
<code>kms</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.KMSSpec">
KMSSpec
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>KMS defines metadata about the kms secret encryption strategy</p>
</td>
</tr>
<tr>
<td>
<code>aescbc</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.AESCBCSpec">
AESCBCSpec
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>AESCBC defines metadata about the AESCBC secret encryption strategy</p>
</td>
</tr>
</tbody>
</table>
###SecretEncryptionType { #hypershift.openshift.io/v1alpha1.SecretEncryptionType }
<p>
(<em>Appears on:</em>
<a href="#hypershift.openshift.io/v1alpha1.SecretEncryptionSpec">SecretEncryptionSpec</a>)
</p>
<p>
<p>SecretEncryptionType defines the type of kube secret encryption being used.</p>
</p>
<table>
<thead>
<tr>
<th>Value</th>
<th>Description</th>
</tr>
</thead>
<tbody><tr><td><p>&#34;aescbc&#34;</p></td>
<td><p>AESCBC uses AES-CBC with PKCS#7 padding to do secret encryption</p>
</td>
</tr><tr><td><p>&#34;kms&#34;</p></td>
<td><p>KMS integrates with a cloud provider&rsquo;s key management service to do secret encryption</p>
</td>
</tr></tbody>
</table>
###ServiceNetworkEntry { #hypershift.openshift.io/v1alpha1.ServiceNetworkEntry }
<p>
(<em>Appears on:</em>
<a href="#hypershift.openshift.io/v1alpha1.ClusterNetworking">ClusterNetworking</a>)
</p>
<p>
<p>ServiceNetworkEntry is a single IP address block for the service network.</p>
</p>
<table>
<thead>
<tr>
<th>Field</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<code>cidr</code></br>
<em>
<a href="#">
github.com/openshift/hypershift/api/util/ipnet.IPNet
</a>
</em>
</td>
<td>
<p>CIDR is the IP block address pool for services within the cluster.</p>
</td>
</tr>
</tbody>
</table>
###ServicePublishingStrategy { #hypershift.openshift.io/v1alpha1.ServicePublishingStrategy }
<p>
(<em>Appears on:</em>
<a href="#hypershift.openshift.io/v1alpha1.ServicePublishingStrategyMapping">ServicePublishingStrategyMapping</a>)
</p>
<p>
<p>ServicePublishingStrategy specfies how to publish a ServiceType.</p>
</p>
<table>
<thead>
<tr>
<th>Field</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<code>type</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.PublishingStrategyType">
PublishingStrategyType
</a>
</em>
</td>
<td>
<p>Type is the publishing strategy used for the service.</p>
</td>
</tr>
<tr>
<td>
<code>nodePort</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.NodePortPublishingStrategy">
NodePortPublishingStrategy
</a>
</em>
</td>
<td>
<p>NodePort configures exposing a service using a NodePort.</p>
</td>
</tr>
<tr>
<td>
<code>loadBalancer</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.LoadBalancerPublishingStrategy">
LoadBalancerPublishingStrategy
</a>
</em>
</td>
<td>
<p>LoadBalancer configures exposing a service using a LoadBalancer.</p>
</td>
</tr>
<tr>
<td>
<code>route</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.RoutePublishingStrategy">
RoutePublishingStrategy
</a>
</em>
</td>
<td>
<p>Route configures exposing a service using a Route.</p>
</td>
</tr>
</tbody>
</table>
###ServicePublishingStrategyMapping { #hypershift.openshift.io/v1alpha1.ServicePublishingStrategyMapping }
<p>
(<em>Appears on:</em>
<a href="#hypershift.openshift.io/v1alpha1.HostedClusterSpec">HostedClusterSpec</a>, 
<a href="#hypershift.openshift.io/v1alpha1.HostedControlPlaneSpec">HostedControlPlaneSpec</a>)
</p>
<p>
<p>ServicePublishingStrategyMapping specifies how individual control plane
services are published from the hosting cluster of a control plane.</p>
</p>
<table>
<thead>
<tr>
<th>Field</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<code>service</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.ServiceType">
ServiceType
</a>
</em>
</td>
<td>
<p>Service identifies the type of service being published.</p>
</td>
</tr>
<tr>
<td>
<code>servicePublishingStrategy</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.ServicePublishingStrategy">
ServicePublishingStrategy
</a>
</em>
</td>
<td>
<p>ServicePublishingStrategy specifies how to publish Service.</p>
</td>
</tr>
</tbody>
</table>
###ServiceType { #hypershift.openshift.io/v1alpha1.ServiceType }
<p>
(<em>Appears on:</em>
<a href="#hypershift.openshift.io/v1alpha1.ServicePublishingStrategyMapping">ServicePublishingStrategyMapping</a>)
</p>
<p>
<p>ServiceType defines what control plane services can be exposed from the
management control plane.</p>
</p>
###UnmanagedEtcdSpec { #hypershift.openshift.io/v1alpha1.UnmanagedEtcdSpec }
<p>
(<em>Appears on:</em>
<a href="#hypershift.openshift.io/v1alpha1.EtcdSpec">EtcdSpec</a>)
</p>
<p>
<p>UnmanagedEtcdSpec specifies configuration which enables the control plane to
integrate with an eternally managed etcd cluster.</p>
</p>
<table>
<thead>
<tr>
<th>Field</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<code>endpoint</code></br>
<em>
string
</em>
</td>
<td>
<p>Endpoint is the full etcd cluster client endpoint URL. For example:</p>
<pre><code>https://etcd-client:2379
</code></pre>
<p>If the URL uses an HTTPS scheme, the TLS field is required.</p>
</td>
</tr>
<tr>
<td>
<code>tls</code></br>
<em>
<a href="#hypershift.openshift.io/v1alpha1.EtcdTLSConfig">
EtcdTLSConfig
</a>
</em>
</td>
<td>
<p>TLS specifies TLS configuration for HTTPS etcd client endpoints.</p>
</td>
</tr>
</tbody>
</table>
###UpgradeStrategy { #hypershift.openshift.io/v1alpha1.UpgradeStrategy }
<p>
(<em>Appears on:</em>
<a href="#hypershift.openshift.io/v1alpha1.ReplaceUpgrade">ReplaceUpgrade</a>)
</p>
<p>
<p>UpgradeStrategy is a specific strategy for upgrading nodes in a NodePool.</p>
</p>
<table>
<thead>
<tr>
<th>Value</th>
<th>Description</th>
</tr>
</thead>
<tbody><tr><td><p>&#34;OnDelete&#34;</p></td>
<td><p>UpgradeStrategyOnDelete replaces old nodes when the deletion of the
associated node instances are completed.</p>
</td>
</tr><tr><td><p>&#34;RollingUpdate&#34;</p></td>
<td><p>UpgradeStrategyRollingUpdate means use a rolling update for nodes.</p>
</td>
</tr></tbody>
</table>
###UpgradeType { #hypershift.openshift.io/v1alpha1.UpgradeType }
<p>
(<em>Appears on:</em>
<a href="#hypershift.openshift.io/v1alpha1.NodePoolManagement">NodePoolManagement</a>)
</p>
<p>
<p>UpgradeType is a type of high-level upgrade behavior nodes in a NodePool.</p>
</p>
<table>
<thead>
<tr>
<th>Value</th>
<th>Description</th>
</tr>
</thead>
<tbody><tr><td><p>&#34;InPlace&#34;</p></td>
<td><p>UpgradeTypeInPlace is a strategy which replaces nodes in-place with no
additional node capacity requirements.</p>
</td>
</tr><tr><td><p>&#34;Replace&#34;</p></td>
<td><p>UpgradeTypeReplace is a strategy which replaces nodes using surge node
capacity.</p>
</td>
</tr></tbody>
</table>
###Volume { #hypershift.openshift.io/v1alpha1.Volume }
<p>
(<em>Appears on:</em>
<a href="#hypershift.openshift.io/v1alpha1.AWSNodePoolPlatform">AWSNodePoolPlatform</a>)
</p>
<p>
<p>Volume specifies the configuration options for node instance storage devices.</p>
</p>
<table>
<thead>
<tr>
<th>Field</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<code>size</code></br>
<em>
int64
</em>
</td>
<td>
<p>Size specifies size (in Gi) of the storage device.</p>
<p>Must be greater than the image snapshot size or 8 (whichever is greater).</p>
</td>
</tr>
<tr>
<td>
<code>type</code></br>
<em>
string
</em>
</td>
<td>
<p>Type is the type of the volume.</p>
</td>
</tr>
<tr>
<td>
<code>iops</code></br>
<em>
int64
</em>
</td>
<td>
<em>(Optional)</em>
<p>IOPS is the number of IOPS requested for the disk. This is only valid
for type io1.</p>
</td>
</tr>
</tbody>
</table>
<hr/>
