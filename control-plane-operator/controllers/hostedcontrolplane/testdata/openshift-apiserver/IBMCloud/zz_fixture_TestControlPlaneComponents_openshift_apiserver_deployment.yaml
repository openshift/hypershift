apiVersion: apps/v1
kind: Deployment
metadata:
  creationTimestamp: null
  labels:
    hypershift.openshift.io/managed-by: control-plane-operator
  name: openshift-apiserver
  namespace: hcp-namespace
  ownerReferences:
  - apiVersion: hypershift.openshift.io/v1beta1
    blockOwnerDeletion: true
    controller: true
    kind: HostedControlPlane
    name: hcp
    uid: ""
  resourceVersion: "1"
spec:
  replicas: 3
  revisionHistoryLimit: 2
  selector:
    matchLabels:
      app: openshift-apiserver
  strategy:
    rollingUpdate:
      maxSurge: 0
      maxUnavailable: 1
    type: RollingUpdate
  template:
    metadata:
      annotations:
        cluster-autoscaler.kubernetes.io/safe-to-evict-local-volumes: work-logs,oas-trust-anchor,tmp-dir
        component.hypershift.openshift.io/config-hash: 19dc307e41f50a7352ebd36a829b997b
        hypershift.openshift.io/release-image: quay.io/openshift-release-dev/ocp-release:4.16.10-x86_64
      creationTimestamp: null
      labels:
        app: openshift-apiserver
        hypershift.openshift.io/control-plane-component: openshift-apiserver
        hypershift.openshift.io/hosted-control-plane: hcp-namespace
    spec:
      affinity:
        nodeAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - preference:
              matchExpressions:
              - key: hypershift.openshift.io/control-plane
                operator: In
                values:
                - "true"
            weight: 50
          - preference:
              matchExpressions:
              - key: hypershift.openshift.io/cluster
                operator: In
                values:
                - hcp-namespace
            weight: 100
        podAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - podAffinityTerm:
              labelSelector:
                matchLabels:
                  hypershift.openshift.io/hosted-control-plane: hcp-namespace
              topologyKey: kubernetes.io/hostname
            weight: 100
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchLabels:
                app: openshift-apiserver
                hypershift.openshift.io/control-plane-component: openshift-apiserver
                hypershift.openshift.io/hosted-control-plane: hcp-namespace
            topologyKey: topology.kubernetes.io/zone
          - labelSelector:
              matchLabels:
                app: openshift-apiserver
                hypershift.openshift.io/control-plane-component: openshift-apiserver
                hypershift.openshift.io/hosted-control-plane: hcp-namespace
            topologyKey: kubernetes.io/hostname
      automountServiceAccountToken: false
      containers:
      - args:
        - start
        - --config=/etc/kubernetes/config/config.yaml
        - --authorization-kubeconfig=/etc/kubernetes/secrets/svc-kubeconfig/kubeconfig
        - --authentication-kubeconfig=/etc/kubernetes/secrets/svc-kubeconfig/kubeconfig
        - --requestheader-client-ca-file=/etc/kubernetes/certs/aggregator-client-ca/ca.crt
        - --requestheader-allowed-names=kube-apiserver-proxy,system:kube-apiserver-proxy,system:openshift-aggregator
        - --requestheader-username-headers=X-Remote-User
        - --requestheader-group-headers=X-Remote-Group
        - --requestheader-extra-headers-prefix=X-Remote-Extra-
        - --client-ca-file=/etc/kubernetes/certs/client-ca/ca.crt
        env:
        - name: HTTP_PROXY
          value: http://127.0.0.1:8090
        - name: HTTPS_PROXY
          value: http://127.0.0.1:8090
        - name: NO_PROXY
          value: kube-apiserver,etcd-client,audit-webhook
        image: openshift-apiserver
        imagePullPolicy: IfNotPresent
        livenessProbe:
          failureThreshold: 3
          httpGet:
            path: livez?exclude=etcd
            port: 8443
            scheme: HTTPS
          periodSeconds: 10
          successThreshold: 1
          timeoutSeconds: 10
        name: openshift-apiserver
        ports:
        - containerPort: 8443
          name: https
          protocol: TCP
        readinessProbe:
          failureThreshold: 10
          httpGet:
            path: readyz?exclude=etcd&exclude=etcd-readiness
            port: 8443
            scheme: HTTPS
          periodSeconds: 10
          successThreshold: 1
          timeoutSeconds: 1
        resources:
          requests:
            cpu: 100m
            memory: 200Mi
        securityContext:
          readOnlyRootFilesystem: true
        startupProbe:
          failureThreshold: 30
          httpGet:
            path: livez
            port: 8443
            scheme: HTTPS
          periodSeconds: 5
          successThreshold: 1
          timeoutSeconds: 10
        terminationMessagePolicy: FallbackToLogsOnError
        volumeMounts:
        - mountPath: /etc/kubernetes/certs/aggregator-client-ca
          name: aggregator-ca
        - mountPath: /etc/kubernetes/audit-config
          name: audit-config
        - mountPath: /etc/kubernetes/certs/client-ca
          name: client-ca
        - mountPath: /etc/kubernetes/config
          name: config
        - mountPath: /etc/kubernetes/certs/etcd-client-ca
          name: etcd-client-ca
        - mountPath: /etc/kubernetes/certs/etcd-client
          name: etcd-client-cert
        - mountPath: /etc/kubernetes/secrets/svc-kubeconfig
          name: kubeconfig
        - mountPath: /etc/pki/ca-trust/extracted/pem
          name: oas-trust-anchor
        - mountPath: /var/lib/kubelet
          name: pull-secret
        - mountPath: /etc/kubernetes/certs/serving
          name: serving-cert
        - mountPath: /var/log/openshift-apiserver
          name: work-logs
        - mountPath: /tmp
          name: tmp-dir
        workingDir: /var/log/openshift-apiserver
      - args:
        - -c
        - |
          set -o errexit
          set -o nounset
          set -o pipefail

          function cleanup() {
            pkill -P $$$
            wait
            exit
          }
          trap cleanup SIGTERM

          /usr/bin/tail -c+1 -F /var/log/openshift-apiserver/audit.log &
          wait $!
        command:
        - /bin/bash
        image: cli
        imagePullPolicy: IfNotPresent
        name: audit-logs
        resources:
          requests:
            cpu: 5m
            memory: 10Mi
        securityContext:
          readOnlyRootFilesystem: true
        terminationMessagePolicy: FallbackToLogsOnError
        volumeMounts:
        - mountPath: /var/log/openshift-apiserver
          name: work-logs
        - mountPath: /tmp
          name: tmp-dir
      - args:
        - run
        command:
        - /usr/bin/control-plane-operator
        - konnectivity-https-proxy
        env:
        - name: KUBECONFIG
          value: /etc/kubernetes/secrets/kubeconfig/kubeconfig
        image: controlplane-operator
        name: konnectivity-proxy-https
        resources:
          requests:
            cpu: 10m
            memory: 30Mi
        securityContext:
          readOnlyRootFilesystem: true
        terminationMessagePolicy: FallbackToLogsOnError
        volumeMounts:
        - mountPath: /etc/kubernetes/secrets/kubeconfig
          name: kubeconfig
        - mountPath: /etc/konnectivity/proxy-client
          name: konnectivity-proxy-cert
        - mountPath: /etc/konnectivity/proxy-ca
          name: konnectivity-proxy-ca
        - mountPath: /tmp
          name: tmp-dir
      initContainers:
      - command:
        - /usr/bin/control-plane-operator
        - availability-prober
        - --target
        - https://kube-apiserver:2040/readyz
        image: availability-prober
        imagePullPolicy: IfNotPresent
        name: availability-prober
        resources: {}
        terminationMessagePolicy: FallbackToLogsOnError
      - command:
        - /bin/bash
        - -c
        - |2

          #!/bin/bash

          set -euo pipefail

          cp -f -r /etc/pki/ca-trust/extracted/pem/* /run/ca-trust-generated/

          if ! [[ -f /run/service-ca-signer/service-ca.crt ]]; then
             exit 0
          fi

          chmod 0666 /run/ca-trust-generated/tls-ca-bundle.pem
          echo '#service signer ca' >> /run/ca-trust-generated/tls-ca-bundle.pem
          cat /run/service-ca-signer/service-ca.crt >>/run/ca-trust-generated/tls-ca-bundle.pem
          chmod 0444 /run/ca-trust-generated/tls-ca-bundle.pem
        image: openshift-apiserver
        imagePullPolicy: IfNotPresent
        name: oas-trust-anchor-generator
        resources: {}
        terminationMessagePolicy: FallbackToLogsOnError
        volumeMounts:
        - mountPath: /run/ca-trust-generated
          name: oas-trust-anchor
      priorityClassName: hypershift-api-critical
      terminationGracePeriodSeconds: 120
      tolerations:
      - effect: NoSchedule
        key: hypershift.openshift.io/control-plane
        operator: Equal
        value: "true"
      - effect: NoSchedule
        key: hypershift.openshift.io/cluster
        operator: Equal
        value: hcp-namespace
      volumes:
      - emptyDir: {}
        name: work-logs
      - configMap:
          defaultMode: 420
          name: openshift-apiserver
        name: config
      - configMap:
          defaultMode: 420
          name: openshift-apiserver-audit
        name: audit-config
      - configMap:
          defaultMode: 420
          name: aggregator-client-ca
        name: aggregator-ca
      - configMap:
          defaultMode: 420
          name: etcd-ca
        name: etcd-client-ca
      - configMap:
          defaultMode: 420
          name: client-ca
        name: client-ca
      - name: kubeconfig
        secret:
          defaultMode: 416
          secretName: service-network-admin-kubeconfig
      - name: serving-cert
        secret:
          defaultMode: 416
          secretName: openshift-apiserver-cert
      - name: etcd-client-cert
        secret:
          defaultMode: 416
          secretName: etcd-client-tls
      - emptyDir: {}
        name: oas-trust-anchor
      - name: pull-secret
        secret:
          defaultMode: 416
          items:
          - key: .dockerconfigjson
            path: config.json
          secretName: pull-secret
      - name: konnectivity-proxy-cert
        secret:
          defaultMode: 416
          secretName: konnectivity-client
      - configMap:
          name: konnectivity-ca-bundle
        name: konnectivity-proxy-ca
      - emptyDir: {}
        name: tmp-dir
status: {}
