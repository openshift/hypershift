apiVersion: apps/v1
kind: StatefulSet
metadata:
  creationTimestamp: null
  name: etcd
  namespace: hcp-namespace
  ownerReferences:
  - apiVersion: hypershift.openshift.io/v1beta1
    blockOwnerDeletion: true
    controller: true
    kind: HostedControlPlane
    name: hcp
    uid: ""
  resourceVersion: "1"
spec:
  persistentVolumeClaimRetentionPolicy:
    whenDeleted: Retain
    whenScaled: Retain
  podManagementPolicy: Parallel
  replicas: 3
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      app: etcd
  serviceName: etcd-discovery
  template:
    metadata:
      annotations:
        component.hypershift.openshift.io/config-hash: ""
        hypershift.openshift.io/release-image: quay.io/openshift-release-dev/ocp-release:4.16.10-x86_64
      creationTimestamp: null
      labels:
        app: etcd
        hypershift.openshift.io/control-plane-component: etcd
        hypershift.openshift.io/hosted-control-plane: hcp-namespace
        hypershift.openshift.io/need-management-kas-access: "true"
    spec:
      affinity:
        nodeAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - preference:
              matchExpressions:
              - key: hypershift.openshift.io/control-plane
                operator: In
                values:
                - "true"
            weight: 50
          - preference:
              matchExpressions:
              - key: hypershift.openshift.io/cluster
                operator: In
                values:
                - hcp-namespace
            weight: 100
        podAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - podAffinityTerm:
              labelSelector:
                matchLabels:
                  hypershift.openshift.io/hosted-control-plane: hcp-namespace
              topologyKey: kubernetes.io/hostname
            weight: 100
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchLabels:
                app: etcd
                hypershift.openshift.io/control-plane-component: etcd
                hypershift.openshift.io/hosted-control-plane: hcp-namespace
                hypershift.openshift.io/need-management-kas-access: "true"
            topologyKey: topology.kubernetes.io/zone
          - labelSelector:
              matchLabels:
                app: etcd
                hypershift.openshift.io/control-plane-component: etcd
                hypershift.openshift.io/hosted-control-plane: hcp-namespace
                hypershift.openshift.io/need-management-kas-access: "true"
            topologyKey: kubernetes.io/hostname
      automountServiceAccountToken: true
      containers:
      - command:
        - /bin/sh
        - -c
        - ETCD_INITIAL_CLUSTER_STATE=$(cat /etc/etcd/clusterstate/state) /usr/bin/etcd
        env:
        - name: POD_IP
          valueFrom:
            fieldRef:
              fieldPath: status.podIP
        - name: NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        - name: HOSTNAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: ETCD_NAME
          value: $(HOSTNAME)
        - name: ETCD_QUOTA_BACKEND_BYTES
          value: "8589934592"
        - name: ETCD_DATA_DIR
          value: /var/lib/data
        - name: ETCD_INITIAL_ADVERTISE_PEER_URLS
          value: https://$(HOSTNAME).etcd-discovery.$(NAMESPACE).svc:2380
        - name: ETCD_LISTEN_PEER_URLS
          value: https://$(POD_IP):2380
        - name: ETCD_LISTEN_CLIENT_URLS
          value: https://$(POD_IP):2379,https://localhost:2379
        - name: ETCD_ADVERTISE_CLIENT_URLS
          value: https://$(HOSTNAME).etcd-discovery.$(NAMESPACE).svc:2379
        - name: ETCD_LISTEN_METRICS_URLS
          value: https://0.0.0.0:2382
        - name: ETCD_SNAPSHOT_COUNT
          value: "10000"
        - name: ETCD_PEER_CLIENT_CERT_AUTH
          value: "true"
        - name: ETCD_PEER_CERT_FILE
          value: /etc/etcd/tls/peer/peer.crt
        - name: ETCD_PEER_KEY_FILE
          value: /etc/etcd/tls/peer/peer.key
        - name: ETCD_PEER_TRUSTED_CA_FILE
          value: /etc/etcd/tls/etcd-ca/ca.crt
        - name: ETCD_CLIENT_CERT_AUTH
          value: "true"
        - name: ETCD_CERT_FILE
          value: /etc/etcd/tls/server/server.crt
        - name: ETCD_KEY_FILE
          value: /etc/etcd/tls/server/server.key
        - name: ETCD_TRUSTED_CA_FILE
          value: /etc/etcd/tls/etcd-ca/ca.crt
        - name: ETCD_ENABLE_PPROF
          value: "true"
        - name: ETCD_INITIAL_CLUSTER
          value: etcd-0=https://etcd-0.etcd-discovery.hcp-namespace.svc:2380
        image: etcd
        imagePullPolicy: IfNotPresent
        livenessProbe:
          failureThreshold: 5
          httpGet:
            path: healthz
            port: 9980
            scheme: HTTPS
          periodSeconds: 5
          successThreshold: 1
          timeoutSeconds: 30
        name: etcd
        ports:
        - containerPort: 2379
          name: client
          protocol: TCP
        - containerPort: 2380
          name: peer
          protocol: TCP
        readinessProbe:
          failureThreshold: 15
          httpGet:
            path: readyz
            port: 9980
            scheme: HTTPS
          periodSeconds: 5
          successThreshold: 1
          timeoutSeconds: 10
        resources:
          requests:
            cpu: 300m
            memory: 600Mi
        startupProbe:
          failureThreshold: 18
          httpGet:
            path: readyz
            port: 9980
            scheme: HTTPS
          periodSeconds: 10
          successThreshold: 1
          timeoutSeconds: 10
        volumeMounts:
        - mountPath: /var/lib
          name: data
        - mountPath: /etc/etcd/tls/peer
          name: peer-tls
        - mountPath: /etc/etcd/tls/server
          name: server-tls
        - mountPath: /etc/etcd/tls/client
          name: client-tls
        - mountPath: /etc/etcd/tls/etcd-ca
          name: etcd-ca
        - mountPath: /etc/etcd/clusterstate
          name: cluster-state
      - args:
        - grpc-proxy
        - start
        - --endpoints=https://localhost:2382
        - --advertise-client-url=""
        - --key=/etc/etcd/tls/peer/peer.key
        - --key-file=/etc/etcd/tls/server/server.key
        - --cert=/etc/etcd/tls/peer/peer.crt
        - --cert-file=/etc/etcd/tls/server/server.crt
        - --cacert=/etc/etcd/tls/etcd-ca/ca.crt
        - --trusted-ca-file=/etc/etcd/tls/etcd-metrics-ca/ca.crt
        - --listen-addr=127.0.0.1:2383
        - --metrics-addr=https://0.0.0.0:2381
        command:
        - etcd
        image: etcd
        imagePullPolicy: IfNotPresent
        name: etcd-metrics
        ports:
        - containerPort: 2381
          name: metrics
          protocol: TCP
        resources:
          requests:
            cpu: 40m
            memory: 200Mi
        volumeMounts:
        - mountPath: /etc/etcd/tls/peer
          name: peer-tls
        - mountPath: /etc/etcd/tls/server
          name: server-tls
        - mountPath: /etc/etcd/tls/etcd-ca
          name: etcd-ca
        - mountPath: /etc/etcd/tls/etcd-metrics-ca
          name: etcd-metrics-ca
      - args:
        - readyz
        - --target=https://localhost:2379
        - --listen-port=9980
        - --serving-cert-file=/etc/etcd/tls/server/server.crt
        - --serving-key-file=/etc/etcd/tls/server/server.key
        - --client-cert-file=/etc/etcd/tls/client/etcd-client.crt
        - --client-key-file=/etc/etcd/tls/client/etcd-client.key
        - --client-cacert-file=/etc/etcd/tls/etcd-ca/ca.crt
        command:
        - cluster-etcd-operator
        image: cluster-etcd-operator
        imagePullPolicy: IfNotPresent
        name: healthz
        ports:
        - containerPort: 9980
          name: healthz
          protocol: TCP
        resources:
          requests:
            cpu: 10m
            memory: 50Mi
        volumeMounts:
        - mountPath: /etc/etcd/tls/server
          name: server-tls
        - mountPath: /etc/etcd/tls/client
          name: client-tls
        - mountPath: /etc/etcd/tls/etcd-ca
          name: etcd-ca
      initContainers:
      - args:
        - -c
        - exec control-plane-operator resolve-dns ${HOSTNAME}.etcd-discovery.${NAMESPACE}.svc
        command:
        - /bin/bash
        env:
        - name: NAMESPACE
          valueFrom:
            fieldRef:
              apiVersion: v1
              fieldPath: metadata.namespace
        image: controlplane-operator
        imagePullPolicy: IfNotPresent
        name: ensure-dns
        resources: {}
      - args:
        - -c
        - |
          #!/bin/bash

          set -eu

          # This script checks whether the data directory of this etcd member is empty.
          # If it is, and there is a functional etcd cluster, then it ensures that a member
          # corresponding to this pod does not exist in the cluster so it can be added
          # as a new member.

          # Setup the etcdctl environment
          export ETCDCTL_API=3
          export ETCDCTL_CACERT=/etc/etcd/tls/etcd-ca/ca.crt
          export ETCDCTL_CERT=/etc/etcd/tls/server/server.crt
          export ETCDCTL_KEY=/etc/etcd/tls/server/server.key
          export ETCDCTL_ENDPOINTS=https://etcd-client:2379

          echo "new" > /etc/etcd/clusterstate/state

          if [[ ! -f /var/lib/data/member/snap/db ]]; then
            echo "No existing etcd data found"
            echo "Checking if cluster is functional"
            if etcdctl member list; then
              echo "Cluster is functional"
              MEMBER_ID=$(etcdctl member list -w simple | grep "${HOSTNAME}" | awk -F, '{ print $1 }')
              if [[ -n "${MEMBER_ID}" ]]; then
                echo "A member with this name (${HOSTNAME}) already exists, removing"
                etcdctl member remove "${MEMBER_ID}"
                echo "Adding new member"
                etcdctl member add ${HOSTNAME} --peer-urls https://${HOSTNAME}.etcd-discovery.${NAMESPACE}.svc:2380
                echo "existing" > /etc/etcd/clusterstate/state
              else
                echo "A member does not exist with name (${HOSTNAME}), nothing to do"
              fi
            else
              echo "Cannot list members in cluster, so likely not up yet"
            fi
          else
            echo "Snapshot db exists, member has data"
          fi
        command:
        - /bin/bash
        env:
        - name: NAMESPACE
          valueFrom:
            fieldRef:
              apiVersion: v1
              fieldPath: metadata.namespace
        image: etcd
        imagePullPolicy: IfNotPresent
        name: reset-member
        resources: {}
        volumeMounts:
        - mountPath: /var/lib
          name: data
        - mountPath: /etc/etcd/tls/server
          name: server-tls
        - mountPath: /etc/etcd/tls/etcd-ca
          name: etcd-ca
        - mountPath: /etc/etcd/clusterstate
          name: cluster-state
      priorityClassName: hypershift-etcd
      restartPolicy: Always
      schedulerName: default-scheduler
      tolerations:
      - effect: NoSchedule
        key: hypershift.openshift.io/control-plane
        operator: Equal
        value: "true"
      - effect: NoSchedule
        key: hypershift.openshift.io/cluster
        operator: Equal
        value: hcp-namespace
      volumes:
      - name: peer-tls
        secret:
          defaultMode: 416
          secretName: etcd-peer-tls
      - name: server-tls
        secret:
          defaultMode: 416
          secretName: etcd-server-tls
      - name: client-tls
        secret:
          defaultMode: 416
          secretName: etcd-client-tls
      - configMap:
          defaultMode: 420
          name: etcd-ca
        name: etcd-ca
      - configMap:
          defaultMode: 420
          name: etcd-metrics-ca
        name: etcd-metrics-ca
      - emptyDir: {}
        name: cluster-state
  updateStrategy:
    rollingUpdate:
      partition: 0
    type: RollingUpdate
  volumeClaimTemplates:
  - metadata:
      creationTimestamp: null
      name: data
    spec:
      accessModes:
      - ReadWriteOnce
      resources:
        requests:
          storage: 8Gi
      volumeMode: Filesystem
    status: {}
status:
  availableReplicas: 0
  replicas: 0
